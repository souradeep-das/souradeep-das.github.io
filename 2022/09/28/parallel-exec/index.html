<!DOCTYPE html>
<html lang=en>
<head>
    <!-- so meta -->
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="HandheldFriendly" content="True">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=5" />
    <meta name="description" content="As developers working with Ethereum, we all know that the Ethereum Layer1 (L1) isn’t very scalable, and that’s what Layer 2 (L2) projects like Boba, Optimism, zkSync etc are committed to address and r">
<meta property="og:type" content="article">
<meta property="og:title" content="Parallel Execution of Transaction in the EVM: Scaling L2s even further">
<meta property="og:url" content="http://example.com/2022/09/28/parallel-exec/index.html">
<meta property="og:site_name" content="Souradeep is typing...">
<meta property="og:description" content="As developers working with Ethereum, we all know that the Ethereum Layer1 (L1) isn’t very scalable, and that’s what Layer 2 (L2) projects like Boba, Optimism, zkSync etc are committed to address and r">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://example.com/images/giphy.gif">
<meta property="og:image" content="http://example.com/images/chart.png">
<meta property="og:image" content="http://example.com/images/struct.png">
<meta property="og:image" content="http://example.com/images/aa_metal.png">
<meta property="article:published_time" content="2022-09-28T15:06:12.000Z">
<meta property="article:modified_time" content="2023-06-26T21:50:14.966Z">
<meta property="article:author" content="Souradeep Das">
<meta property="article:tag" content="Research">
<meta property="article:tag" content="EVM">
<meta property="article:tag" content="Rollup">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/images/giphy.gif">
    
    
      
        
          <link rel="shortcut icon" href="/images/favicon4.ico">
        
      
      
        
          <link rel="icon" type="image/png" href="/images/favicon-192x192_4.png" sizes="192x192">
        
      
      
        
          <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon4.png">
        
      
    
    <!-- title -->
    
      <title>Souradeep's Blog: Parallel Execution of Transaction in the EVM: Scaling L2s even further</title>
    
    <!-- async scripts -->
    <!-- Google Analytics -->


    <!-- Umami Analytics -->


    <!-- styles -->
    
<link rel="stylesheet" href="/css/style.css">

    <!-- persian styles -->
    
    <!-- rss -->
    
    
	<!-- mathjax -->
	
<meta name="generator" content="Hexo 6.3.0"></head>

<body class="max-width mx-auto px3 ltr">
    
      <div id="header-post">
  <a id="menu-icon" href="#" aria-label="Menu"><i class="fa-solid fa-bars fa-lg"></i></a>
  <a id="menu-icon-tablet" href="#" aria-label="Menu"><i class="fa-solid fa-bars fa-lg"></i></a>
  <a id="top-icon-tablet" href="#" aria-label="Top" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');" style="display:none;"><i class="fa-solid fa-chevron-up fa-lg"></i></a>
  <span id="menu">
    <span id="nav">
      <ul>
        <!--
       --><li><a href="/">Home</a></li><!--
     --><!--
       --><li><a href="/about/">About</a></li><!--
     --><!--
       --><li><a href="/archives/">Writing</a></li><!--
     --><!--
       --><li><a href="/search/">Search</a></li><!--
     -->
      </ul>
    </span>
    <br/>
    <span id="actions">
      <ul>
        
        <li><a class="icon" aria-label="Previous post" href="/2023/05/06/uni-v3/"><i class="fa-solid fa-chevron-left" aria-hidden="true" onmouseover="$('#i-prev').toggle();" onmouseout="$('#i-prev').toggle();"></i></a></li>
        
        
        <li><a class="icon" aria-label="Next post" href="/2021/03/24/quasar-pool/"><i class="fa-solid fa-chevron-right" aria-hidden="true" onmouseover="$('#i-next').toggle();" onmouseout="$('#i-next').toggle();"></i></a></li>
        
        <li><a class="icon" aria-label="Back to top" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');"><i class="fa-solid fa-chevron-up" aria-hidden="true" onmouseover="$('#i-top').toggle();" onmouseout="$('#i-top').toggle();"></i></a></li>
        <li><a class="icon" aria-label="Share post" href="#"><i class="fa-solid fa-share-alt" aria-hidden="true" onmouseover="$('#i-share').toggle();" onmouseout="$('#i-share').toggle();" onclick="$('#share').toggle();return false;"></i></a></li>
      </ul>
      <span id="i-prev" class="info" style="display:none;">Previous post</span>
      <span id="i-next" class="info" style="display:none;">Next post</span>
      <span id="i-top" class="info" style="display:none;">Back to top</span>
      <span id="i-share" class="info" style="display:none;">Share post</span>
    </span>
    <br/>
    <div id="share" style="display: none">
      <ul>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.facebook.com/sharer.php?u=http://example.com/2022/09/28/parallel-exec/"><i class="fab fa-facebook " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://twitter.com/share?url=http://example.com/2022/09/28/parallel-exec/&text=Parallel Execution of Transaction in the EVM: Scaling L2s even further"><i class="fab fa-twitter " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.linkedin.com/shareArticle?url=http://example.com/2022/09/28/parallel-exec/&title=Parallel Execution of Transaction in the EVM: Scaling L2s even further"><i class="fab fa-linkedin " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://pinterest.com/pin/create/bookmarklet/?url=http://example.com/2022/09/28/parallel-exec/&is_video=false&description=Parallel Execution of Transaction in the EVM: Scaling L2s even further"><i class="fab fa-pinterest " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="mailto:?subject=Parallel Execution of Transaction in the EVM: Scaling L2s even further&body=Check out this article: http://example.com/2022/09/28/parallel-exec/"><i class="fa-solid fa-envelope " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://getpocket.com/save?url=http://example.com/2022/09/28/parallel-exec/&title=Parallel Execution of Transaction in the EVM: Scaling L2s even further"><i class="fab fa-get-pocket " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://reddit.com/submit?url=http://example.com/2022/09/28/parallel-exec/&title=Parallel Execution of Transaction in the EVM: Scaling L2s even further"><i class="fab fa-reddit " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.stumbleupon.com/submit?url=http://example.com/2022/09/28/parallel-exec/&title=Parallel Execution of Transaction in the EVM: Scaling L2s even further"><i class="fab fa-stumbleupon " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://digg.com/submit?url=http://example.com/2022/09/28/parallel-exec/&title=Parallel Execution of Transaction in the EVM: Scaling L2s even further"><i class="fab fa-digg " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.tumblr.com/share/link?url=http://example.com/2022/09/28/parallel-exec/&name=Parallel Execution of Transaction in the EVM: Scaling L2s even further&description="><i class="fab fa-tumblr " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://news.ycombinator.com/submitlink?u=http://example.com/2022/09/28/parallel-exec/&t=Parallel Execution of Transaction in the EVM: Scaling L2s even further"><i class="fab fa-hacker-news " aria-hidden="true"></i></a></li>
</ul>

    </div>
    
    
      <div id="toc">
        <ol class="toc"><li class="toc-item toc-level-5"><a class="toc-link" href="#But-here%E2%80%99s-the-thing-about-scaling-Over-time-there%E2%80%99s-always-more-demand-for-scale-than-any-one-solution-to-the-problem-can-provide-Such-is-the-tyranny-of-distributed-systems"><span class="toc-number">1.</span> <span class="toc-text">But here’s the thing about scaling. Over time, there’s always more demand for scale than any one solution to the problem can provide. Such is the tyranny of distributed systems!</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Breaking-the-Bottlenecks"><span class="toc-number"></span> <span class="toc-text">Breaking the Bottlenecks</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Amping-Up-the-EVM"><span class="toc-number"></span> <span class="toc-text">Amping Up the EVM</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Long-Run-Solutions"><span class="toc-number"></span> <span class="toc-text">Long Run Solutions</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#What-We-Can-Do-Today"><span class="toc-number"></span> <span class="toc-text">What We Can Do Today</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Discussing-Different-Approaches-to-L2-Parallelization"><span class="toc-number"></span> <span class="toc-text">Discussing Different Approaches to L2 Parallelization</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Discussion-1-Give-away-EVM-compatibility-x2F-equivalence"><span class="toc-number"></span> <span class="toc-text">Discussion:1 Give away EVM compatibility&#x2F;equivalence</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Discussion-2-Speculative-Concurrency"><span class="toc-number"></span> <span class="toc-text">Discussion 2: Speculative Concurrency</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Approximating-efficiency-of-general-speculative-concurrency-through-the-eyes-of-an-actively-operating-L2"><span class="toc-number"></span> <span class="toc-text">Approximating efficiency of general speculative concurrency through the eyes of an actively operating L2:</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Discussion-3-Parallel-execution-with-Access-Lists"><span class="toc-number"></span> <span class="toc-text">Discussion 3: Parallel execution with Access Lists</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#What-if-wallets-add-support-for-the-tx-type-How-do-we-still-go-from-%E2%80%98optional%E2%80%99-to-%E2%80%98strict%E2%80%99-access-lists-and-enable-parallelization-on-L2"><span class="toc-number"></span> <span class="toc-text">What if wallets add support for the tx-type? How do we still go from ‘optional’ to ‘strict’ access lists and enable parallelization on L2?</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Two-Proposals"><span class="toc-number"></span> <span class="toc-text">Two Proposals:</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Proposal-1-Method-Access-Boundaries"><span class="toc-number"></span> <span class="toc-text">Proposal 1: Method Access Boundaries</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Proposal-2-Meta-AL-Transactions-and-Account-Abstraction"><span class="toc-number"></span> <span class="toc-text">Proposal 2: Meta AL Transactions and Account Abstraction</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#So-long-and-thanks-for-all-the-fish"><span class="toc-number"></span> <span class="toc-text">So long and thanks for all the fish</span></a>
      </div>
    
  </span>
</div>

    
    <div class="content index py4 ">
        
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">
  <header>
    <!-- 
    <h1 class="posttitle p-name" itemprop="name headline">
        Parallel Execution of Transaction in the EVM: Scaling L2s even further
    </h1>


 -->
    <!-- just remove the below if not needed -->
    
    
    
    
    
    <h1 class="posttitle">
      Parallel Execution of Transaction in the EVM:
      
        <br>
        <span class="subheading"><em>Scaling L2s even further</em></span>
      
    </h1>
    
    

    <div class="meta">
      <!-- <span class="author p-author h-card" itemprop="author" itemscope itemtype="http://schema.org/Person">
        <span class="p-name" itemprop="name">Souradeep Das</span>
      </span> -->
      
    <div class="postdate">
      
        <time datetime="2022-09-28T15:06:12.000Z" class="dt-published" itemprop="datePublished">2022-09-28</time>
        
      
    </div>


      <span class="reading-time">
      <i class="fa-regular fa-clock"></i>
      31 minute read
      </span>
      

      <!-- 
    <div class="article-tag">
        <i class="fa-solid fa-tag"></i>
        <a class="p-category" href="/tags/EVM/" rel="tag">EVM</a>, <a class="p-category" href="/tags/Research/" rel="tag">Research</a>, <a class="p-category" href="/tags/Rollup/" rel="tag">Rollup</a>
    </div>
 -->


    <div class="article-tag">
      <i class="fa-solid fa-tag"></i>
      
        <a href="/tags/Research/">#Research</a>
        
          ,
        
      
        <a href="/tags/EVM/">#EVM</a>
        
          ,
        
      
        <a href="/tags/Rollup/">#Rollup</a>
        
      
    </div>
  
  
  

    </div>
  </header>
  

  <div class="content e-content" itemprop="articleBody">
    <p>As developers working with Ethereum, we all know that the Ethereum Layer1 (L1) isn’t very scalable, and that’s what Layer 2 (L2) projects like Boba, Optimism, zkSync etc are committed to address and resolve in their own way.</p>
<p>Of course, there are several approaches to scaling - on-chain approaches<br>like Sharding parallelizes execution by splitting the network into<br>multiple shards. And the L2 approach takes transaction execution<br>off-chain, using the L1 as a settlement layer through rollups or other<br>techniques.</p>
<h5 id="But-here’s-the-thing-about-scaling-Over-time-there’s-always-more-demand-for-scale-than-any-one-solution-to-the-problem-can-provide-Such-is-the-tyranny-of-distributed-systems"><a href="#But-here’s-the-thing-about-scaling-Over-time-there’s-always-more-demand-for-scale-than-any-one-solution-to-the-problem-can-provide-Such-is-the-tyranny-of-distributed-systems" class="headerlink" title="But here’s the thing about scaling. Over time, there’s always more demand for scale than any one solution to the problem can provide. Such is the tyranny of distributed systems!"></a>But here’s the thing about scaling. Over time, there’s always more demand for scale than any one solution to the problem can provide. Such is the tyranny of distributed systems!</h5><p>That means a L2’s job is never done, or in general any solution for<br>scalability is not truly complete. As is the case, the community is<br>always looking for better ways to increase throughput and reduce latency<br>to meet the ever-increasing demand of projects spanning the internet<br>that need transaction finality across many organizations without<br>sacrificing performance or reliability.</p>
<p>[In this article we are going to get into some approaches that could<br>push the boundaries of scalability even further, including some new<br>methods that can be considered - specifically addressed around a single<br>bottleneck. We will also try and weigh the pros and cons of each, to<br>identify the most promising path forward.]{.mark}</p>
<h2 id="Breaking-the-Bottlenecks"><a href="#Breaking-the-Bottlenecks" class="headerlink" title="Breaking the Bottlenecks"></a>Breaking the Bottlenecks</h2><p>Scaling one part of a system without scaling the bottlenecks around it<br>doesn’t get you far. While some of the more prominent reasons that limit<br>scalability are consensus and propagation of messages (in turn the block<br>size and time), the Ethereum Virtual Machine (EVM) is itself, in its<br>core, a crucial limiter of scale. And, since several L2s would still<br>want to utilize and maintain EVM compatibility&#x2F;equivalence to replicate<br>L1 user experience - they also inherently need to, and are more suitable<br>for finding ways to get around this bottleneck.<br>So the natural question is - what exactly is this bottleneck and how do<br>we get around this?</p>
<h2 id="Amping-Up-the-EVM"><a href="#Amping-Up-the-EVM" class="headerlink" title="Amping Up the EVM"></a>Amping Up the EVM</h2><p>Y(S, T)&#x3D; S&#39;</p>
<p>Ethereum is a state machine, and the EVM executes transactions sequentially, one by one. It doesn’t execute other transactions until the execution of the current transaction is completed and the resulting state is computed. This is to avoid state&#x2F;storage collisions and preserve atomicity of transactions. In other words, this ensures that each transaction is a self-contained, atomic unit of operation that changes the system’s state without interference from or interference to any other concurrent transactions. The execution, however, is still sequential, even with a set of completely independent transactions, because the EVM isn’t designed to be able to execute them at the same time.</p>
<p><img src="/images/giphy.gif" alt="Sequential Tx"></p>
<p>Despite this being a fundamental feature, it remains a bottleneck for the performance of the network and can limit the throughput of Ethereum or any EVM chain.<br>Especially for an L2 where other limitations to scalability like consensus(and message propagation) might not exist, serial execution can turn out to be a more pronounced limitation. Additionally, the L2 as an execution layer for the L1, could be an easier and more suitable ground for implementing approaches to go around the bottleneck and scale maximally.</p>
<p>This brings in the need for parallel execution of transactions, and more so, in an L2 context.</p>
<p>We can think of parallel execution to be possible at two levels:</p>
<ol>
<li><p>Parallel at the transaction level - treat each transaction as the<br>smallest unit for parallelization and execute them on multiple<br>threads.</p>
</li>
<li><p>Parallel at the opcode level - treat each operation as the smallest<br>unit and parallelize opcodes, memory access, etc for multiple<br>transactions.</p>
</li>
</ol>
<p>While parallelizing at the transaction level is relatively<br>straightforward and could produce considerable throughput improvements,<br>parallelizing at the opcode level will attain maximum scalability.<br>However, the latter approach is inherently more complex. We will focus<br>on the first approach to begin with, and discuss it throughout the rest<br>of the article.</p>
<h2 id="Long-Run-Solutions"><a href="#Long-Run-Solutions" class="headerlink" title="Long Run Solutions"></a>Long Run Solutions</h2><p>If we further narrow it down, storage access is where the EVM spends<br>most time while executing a transaction. And when executed sequentially,<br>it represents a significant portion of the overall execution time.<br>Optimizing storage access, hence, could be an important step in enabling<br>parallel execution.<br>At the same time, much of Ethereum’s ongoing research efforts have been<br>on statelessness, witnesses, and light clients, which could enable<br>pre-fetching or optimizing storage accesses. Furthermore, Sharding would<br>split the network into multiple smaller networks (shards), and would<br>theoretically parallelize execution with the design. Things would be<br>easier for the L1, with all of these implemented in the future.</p>
<h2 id="What-We-Can-Do-Today"><a href="#What-We-Can-Do-Today" class="headerlink" title="What We Can Do Today"></a>What We Can Do Today</h2><p>Until these future enhancements arrive, there are ways to address<br>parallel execution that can be made practical today.</p>
<p>Here are a few, of the numerous approaches people have thought about<br>achieving concurrency:</p>
<p>a)  UTXO based blockchain - This is much easier because a UTXO spending<br>    transaction has the unspent outputs (which are also signed) as<br>    inputs for every transaction, and that makes it easy to identify<br>    the storage slots that are going to be affected.</p>
<p>b)  Speculative concurrency - Attempt executing every transaction in<br>    parallel, transactions with conflicts are scheduled at the end.</p>
<p>c)  Speculative concurrency with role-based separation of nodes - Some<br>    nodes participate in ordering (e.g., grouping transactions<br>    together) and some execute.</p>
<p>d)  Storage access lists provided as an input for transactions - To help<br>    identify what storage (or which contracts) the transaction will<br>    access.</p>
<p>e)  Predicting access lists or speculatively generating and caching<br>    (e.g., estimateGas).</p>
<p>f)  Static analysis of contracts or bytecode analysis to determine<br>    access lists ( e.g., commutative operations, even with collisions,<br>    can produce a correct state).</p>
<p>At a high level, all of the following (except UTXO) fall into one of<br>these two groups*:</p>
<ol>
<li><p>Speculative concurrency</p>
</li>
<li><p>Access Lists</p>
</li>
</ol>
<p>* there are certain methods (apart from the list above) that may not<br>fall into either group, but the above classification is good enough for<br>most approaches</p>
<h2 id="Discussing-Different-Approaches-to-L2-Parallelization"><a href="#Discussing-Different-Approaches-to-L2-Parallelization" class="headerlink" title="Discussing Different Approaches to L2 Parallelization"></a>Discussing Different Approaches to L2 Parallelization</h2><p>Let&#39;s continue to assess each of these groups, and find out what each<br>of these approaches could mean for an EVM compatible Layer2, but before<br>that, I bet you are thinking - what about the UTXO model?</p>
<h3 id="Discussion-1-Give-away-EVM-compatibility-x2F-equivalence"><a href="#Discussion-1-Give-away-EVM-compatibility-x2F-equivalence" class="headerlink" title="Discussion:1 Give away EVM compatibility&#x2F;equivalence"></a>Discussion:1 Give away EVM compatibility&#x2F;equivalence</h3><p>A chain&#x2F;L2 based on the UTXO model is easier to parallelize than an<br>account based model. In the former, a transaction is generally a<br>spending transaction and includes the unspent outputs that it is willing<br>to spend (along with proper signatures of the inputs) for the<br>transaction to be valid. This provides for a perfect opportunity to<br>group together transactions that do not spend the same inputs, and<br>execute them in parallel.</p>
<p>However, a chain based on UTXO model isn’t EVM equivalent, and loses out<br>on the advantages of the existing Ethereum toolset, code and developers.</p>
<p><em>Fuel, Findora are some of the popular examples today, which enforce<br>parallelization and utilize a UTXO model.</em></p>
<p><em>Additionally:</em></p>
<p><em>The UTXO model can be extended to have parallel validation with<br>utreexo-<br><a target="_blank" rel="noopener" href="https://blog.bitmex.com/faster-blockchain-validation-with-utreexo-accumulators/">[https://blog.bitmex.com/faster-blockchain-validation-with-utreexo-accumulators/]</a></em></p>
<p><em>And, there are some chains that use both UTXO and account model like<br>Findora<br><a target="_blank" rel="noopener" href="https://wiki.findora.org/docs/modules/prism/Overview/">[https://wiki.findora.org/docs/modules/prism/Overview/]</a></em></p>
<p><em>Smart contracts with UTXO account model and parallelization is also<br>possible<br><a target="_blank" rel="noopener" href="https://forum.celestia.org/t/accounts-strict-access-lists-and-utxos/37">[https://forum.celestia.org/t/accounts-strict-access-lists-and-utxos/37]</a></em></p>
<p>But, even considering the successful implementation of these<br>possibilities, the chain would still not be EVM equivalent.</p>
<p>Going back to the two groups we previously agreed upon, let’s discuss<br>each of them in more detail-</p>
<h3 id="Discussion-2-Speculative-Concurrency"><a href="#Discussion-2-Speculative-Concurrency" class="headerlink" title="Discussion 2: Speculative Concurrency"></a>Discussion 2: Speculative Concurrency</h3><p>Speculative Concurrency appears to be a very popular strategy for<br>parallel execution. A lot of research has been done, lots of ideas<br>shared and several optimizations to speculative concurrency have been<br>proposed.</p>
<p>The general idea of speculative concurrency is to execute transactions<br>in parallel threads speculatively. If there were collisions (common<br>state access) between these transactions, they are discarded and rerun<br>sequentially later.<br><br>Adding on to this general idea, there have been several proposals<br>towards improving Speculative concurrency such as - ‘Separation of nodes<br>with speculative concurrency’ - which involves distributing the network<br>into nodes, who have separate roles - mainly a distinction between those<br>that participate in ordering and some that execute<br>For ex -<br><a target="_blank" rel="noopener" href="https://sites.cs.ucsb.edu/~amiri/papers/oxii.pdf">[ParBlockchain]</a>,<br><a target="_blank" rel="noopener" href="https://www.usenix.org/system/files/atc21-ponnapalli.pdf">[Rainblock]</a><br>(Validator nodes, IO nodes), Flow from Dapper Labs (separation of<br>consensus and compute)</p>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2203.06871.pdf">[‘BlockSTM’]</a> is<br>another proposal that is ‘built around principles of Software<br>Transactional Memory’. It increases efficiency through dynamic<br>dependency estimation and a smart scheduler.</p>
<p>Some other ideas further add to this with dependency graphs, locks and<br>static&#x2F;bytecode analysis.<br><a target="_blank" rel="noopener" href="https://www.microsoft.com/en-us/research/uploads/prod/2021/09/3477132.3483564.pdf">[Forerunner]</a><br>produces constraints based on multi future predictors and speeds<br>execution through the constraints.<br>But, while there are various proposals, it is challenging to accurately<br>evaluate its effectiveness in practice.</p>
<p>The current concerns with Speculative concurrency have been:</p>
<ul>
<li><p>It involves a lot of aborting tx and re-executing - which brings in<br>the need for pricing, otherwise this could open up to DoS attacks</p>
</li>
<li><p>Several of these methods might include changes on a protocol level</p>
</li>
<li><p>Speculative concurrency can suffer from penalties if a lot of tx<br>have conflicts and have to be scheduled again.</p>
</li>
<li><p>If the execution time of one tx in a batch is significantly more<br>than the others, speculative concurrency will yield only minor<br>benefits</p>
</li>
<li><p>It also depends on the activity of the network, types of<br>transactions and the size of the chain among other things, which<br>are hard to generalize, so the efficiency might not be<br>deterministic</p>
</li>
</ul>
<p>‘An Empirical Study of Speculative Concurrency in Ethereum Smart<br>Contracts’ by Seraph et al (<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1901.01376.pdf">https://arxiv.org/pdf/1901.01376.pdf</a>) is a<br>great work of analysis on general speculative concurrency (without<br>additional improvements) and its performance.</p>
<p>Some of their results have been “directly quoted” here:</p>
<ul>
<li><p><em>When txs are optimistically executed, conflict grows as blockchain<br>is more crowded, generally 35% clash rate</em></p>
</li>
<li><p><em>“Accurate static conflict analysis may yield a modest benefit”</em></p>
</li>
<li><p><em>“In high-contention periods, most contention resulted from a very<br>small number of popular contracts”</em></p>
</li>
<li><p><em>“Today, contract writers have no motivation for avoiding such<br>conflicts. It could be productive to devise incentives, perhaps in<br>the form of reduced gas prices, for contracts that produce fewer<br>data conflicts.”</em> (we will discuss about this under method access<br>boundaries)</p>
</li>
<li><p><em>“Speculative techniques typically work well when conflicts are<br>rare, but perform poorly when conflicts are common”</em></p>
</li>
</ul>
<p>The results of speculative concurrency could indeed be subjective, but<br>to still find an estimation of the effects such a model could have -<br>lets try looking back!</p>
<h4 id="Approximating-efficiency-of-general-speculative-concurrency-through-the-eyes-of-an-actively-operating-L2"><a href="#Approximating-efficiency-of-general-speculative-concurrency-through-the-eyes-of-an-actively-operating-L2" class="headerlink" title="Approximating efficiency of general speculative concurrency through the eyes of an actively operating L2:"></a>Approximating efficiency of general speculative concurrency through the eyes of an actively operating L2:</h4><p><a target="_blank" rel="noopener" href="https://boba.network/">[Boba Network]</a> is an Optimistic<br>Rollup with a considerable size (record) of transactions ranging<br>throughout a year. It houses several defi dapps, games, tokens, hybrid<br>compute applications which brings in a variety of types of transactions<br>and thus is a suitable candidate for the L2 whose eyes we want to<br>borrow.</p>
<p>From these past records of transactions on the network, we tried to<br>extract information pertaining to each (transaction), namely the storage<br>accesses (read&#x2F;write) in the hopes of estimating what efficiency<br>speculative concurrency, if it were to exist, would bring to the<br>network.<br>The results, that follow, are based on around 10,000 transactions from<br>Boba’s history around block ranges (365k-370k) and (795k-800k). While<br>the range is an indicator for expected behavior, there is scope for<br>varying the ranges and comparing the results.</p>
<p>Boba, as is the case with Optimistic Rollup design, does not have a<br>mempool currently that could clearly reveal the collisions based on the<br>execution time by the sequencer. For approximation, transactions with<br>close proximity have been grouped together (in groups of 3 and 5) as an<br>estimate of what mempool&#x2F; concurrent transactions could look like (in<br>the future).</p>
<p>Furthermore, collisions at two different levels have been represented<br>distinctly:</p>
<p>i) Collisions at a contract access level (i.e. two or more transactions<br>that access the same addresses)</p>
<p>ii) Collisions at the storage level to check exact parallelizability<br>(i.e. two or more transactions that access the same storage slots of<br>these addresses)</p>
<p>The storage access information from these historical transactions also<br>include operations on the storage slots that each transaction performs.</p>
<p>Between two transactions (tx1, tx2) and their operations on a specific<br>storage slot-</p>
<p>(read, read) - works for concurrency</p>
<p>(read, write) and (write, read) - does not</p>
<p>(write, write) - mostly does not, unless operations are commutative</p>
<p><img src="/images/chart.png" alt="Chart"></p>
<p>*Total groups: number of groups of txs, (approximate grouping around<br>proximity of tx - think blocks)</p>
<p>*Collision addresses: Groups that have collisions based on the addresses<br>they access<br>If two or more txs in a group access a common addresses, we treat the<br>group for having address collisions</p>
<p>Collision Storage slots: Groups that have collisions based on the<br>storage slots of addresses they access. If two or more txs in a group<br>access the same slots in the same addresses, we treat the group for<br>having storage slot collisions*</p>
<p>Results from both of these block durations show that conflicts could be<br>expected to be quite common (in this case), and general speculative<br>concurrency (without improvements), though absolutely worth trying,<br>could yield uncertain results.</p>
<h3 id="Discussion-3-Parallel-execution-with-Access-Lists"><a href="#Discussion-3-Parallel-execution-with-Access-Lists" class="headerlink" title="Discussion 3: Parallel execution with Access Lists"></a>Discussion 3: Parallel execution with Access Lists</h3><p>Access lists for parallel execution, proposed with ‘Easy<br>parallelizability’<br>(<a target="_blank" rel="noopener" href="https://github.com/ethereum/EIPs/issues/648">[https://github.com/ethereum/EIPs/issues/648]</a>)<br>is one of the other lines of thinking about the problem. This involves<br>creating a new tx type that allows users to specify the addresses and<br>storage slots a transaction will access (read&#x2F;write), as a part of the<br>transaction object. The transactions which have disjoint sets can then<br>be executed in parallel.</p>
<p>Solana utilizes a system similar to access lists to enable parallel<br>execution -<br><a target="_blank" rel="noopener" href="https://medium.com/solana-labs/sealevel-parallel-processing-thousands-of-smart-contracts-d814b378192">[SeaLevel]</a> -<br>where storage access info is embedded into the transaction as<br>instructions (address and operation) to prefetch them for execution,<br><a target="_blank" rel="noopener" href="https://sui.io/">[Sui]</a> has a similar approach to Solana.</p>
<p>The main problem with access lists is the difficulty of knowing which<br>states and slots a transaction would affect in advance, without<br>executing the transaction. There exists rpc endpoints like<br>eth_createAccessLists<br>(<a target="_blank" rel="noopener" href="https://geth.ethereum.org/docs/rpc/ns-eth#eth_createaccesslist">[https://geth.ethereum.org/docs/rpc/ns-eth#eth_createaccesslist]</a>)<br>which simulates to estimate access lists based on the state of the prior<br>block. Static analysis of bytecode could also be effective in predicting<br>access lists for a tx<br>(<a target="_blank" rel="noopener" href="https://github.com/alexchenzl/predict-al">[https://github.com/alexchenzl/predict-al]</a>)</p>
<p>Based on current community discussions and strategies, access lists<br>appear to be the most promising and effective approach for enabling<br>concurrency in the EVM. The usage of Access lists would typically not<br>involve modifying the EVM or adding an additional layer to achieve the<br>goal. Furthermore, it is closer to and can gain from several ongoing<br>research efforts like Ethereum’s Statelessness&#x2F;Witnesses generation,<br>which can be very close to obtaining strict access lists. Optional<br>Access lists<br>(<a target="_blank" rel="noopener" href="https://eips.ethereum.org/EIPS/eip-2930">[https://eips.ethereum.org/EIPS/eip-2930]</a>)<br>(<a target="_blank" rel="noopener" href="https://eips.ethereum.org/EIPS/eip-2929#implementation">[https://eips.ethereum.org/EIPS/eip-2929]</a>)<br>is already enforced on L1 allowing to prefetch states on the basis of<br>optional access lists (although not for parallelization).</p>
<p>But in order to implement parallel execution, access lists have to be<br>made strict - they should be maximally complete, so as to know exactly<br>which transactions can be executed concurrently in parallel and avoid<br>penalties for clashes while execution.</p>
<p>Currently Ethereum has ‘Optional Access Lists’ implemented through a new<br>Tx type. But is it possible to make this a compulsion (strict) and<br>enforce concurrency on the network? The assumptions are - a)<br>toolset&#x2F;libraries&#x2F;rpc endpoints for the new tx type exists, but several<br>of the most popular user wallet do not support the tx type yet, and at<br>least some wallet will remain without support b) Users do not know or do<br>not want to generate access lists or use scripts for sending txs.<br>Furthermore, it is very difficult to know which states and slots a tx<br>would affect without executing the transaction.</p>
<p>Broadly, the questions that must be answered for enforcing access lists<br>are-</p>
<ol>
<li><p>How to generate an almost correct and complete access list?</p>
</li>
<li><p>Who generates access lists for the users?</p>
</li>
</ol>
<h3 id="What-if-wallets-add-support-for-the-tx-type-How-do-we-still-go-from-‘optional’-to-‘strict’-access-lists-and-enable-parallelization-on-L2"><a href="#What-if-wallets-add-support-for-the-tx-type-How-do-we-still-go-from-‘optional’-to-‘strict’-access-lists-and-enable-parallelization-on-L2" class="headerlink" title="What if wallets add support for the tx-type? How do we still go from ‘optional’ to ‘strict’ access lists and enable parallelization on L2?"></a>What if wallets add support for the tx-type? How do we still go from ‘optional’ to ‘strict’ access lists and enable parallelization on L2?</h3><p>If wallets were to enable the new transaction type, they might use<br>`eth_createAccessList` to estimate the access list for the<br>transaction. But, there is a possibility that this access list will not<br>be accurate when the transaction is actually executed (since estimation<br>would involve using a prior older state). And as per the demand, for<br>transactions with strict access lists, any transaction with incomplete<br>or incorrect (optional) access lists may be either reverted or queued to<br>be executed sequentially. We could however still utilize Ethereum’s<br>existing transaction types without having to create a new one, although,<br>It is important to maintain the distinction between the original<br>&quot;optional&quot; element for prefetching states and the &quot;strict&quot; element<br>where a transaction can be reverted if it does not provide a complete<br>access list.</p>
<p>As a solution, an opt-in mechanism with a precompile on the network can<br>be made use of to switch between optional (default) and strict<br>(parallelization) choices for each user. Subsequently, when a user&#39;s<br>access list choice is set to ‘strict’, any access outside the specified<br>list should be unsuccessful.</p>
<h2 id="Two-Proposals"><a href="#Two-Proposals" class="headerlink" title="Two Proposals:"></a>Two Proposals:</h2><p>But, Irrespective of whether tools exist for the generation of access<br>lists, the question remains: can we do more?</p>
<p>Here are two proposals.</p>
<h2 id="Proposal-1-Method-Access-Boundaries"><a href="#Proposal-1-Method-Access-Boundaries" class="headerlink" title="Proposal 1: Method Access Boundaries"></a>Proposal 1: Method Access Boundaries</h2><p>It is common for most transactions on a blockchain to primarily involve<br>only a few types of smart contracts. If each transaction includes<br>additional data in the form of access lists, it is likely that there<br>will be repeated patterns of similar access lists with similar calls to<br>contracts.</p>
<p>For a new line of thought, contracts themselves could be the ones to<br>specify access lists, instead of the transaction sender in some cases.<br>In other words, transactions are directed to accounts, and these<br>accounts may have internal calls to other accounts. (we are interested<br>in contract accounts only, since transactions from EOAs to EOAs already<br>have all the information to parallelize), If each contract, on this<br>chain of calls - were to have their own method access boundaries<br>(meaning) - “could bound the addresses that each of the methods in the<br>contract are able to access” (indefinite is a valid option) - we could<br>be closer to finding out intersections and storage collisions between<br>transactions before they are executed.</p>
<p>In addition to being a potential way to execute transactions<br>concurrently, pre-specified method access boundaries could also be a way<br>to enforce higher security standards for a contract by dictating what<br>external methods&#x2F;addresses a contract is allowed&#x2F;supposed to call.</p>
<p>Several contracts do have complicated logic, there are contracts (or<br>methods) that allow arbitrary calls, for instance contract wallets,<br>there are proxy contracts which would not really benefit from method<br>access boundaries (these will have ‘indefinite’ boundaries), but on the<br>other hand a lot of general transactions would. Method Access Boundaries<br>when used in combination with other parallelization techniques could<br>result in an increased efficiency.</p>
<p>The goal is to encourage the creation of contracts that can be maximally<br>parallelizable or have clearly defined method access boundaries, in<br>order to improve scalability at the layer.</p>
<p>One such model including access boundaries is envisioned below.</p>
<p>Specifications:</p>
<ul>
<li>Have an optional extra storage layer for storing the access<br>boundaries of each contract account (specifically definite for<br>each of the methods of the contract account)</li>
</ul>
<p>Storage can be optional for nodes. This could also work with multiple<br>sequencers, where some sequencers use this storage layer and could<br>support method access boundaries for parallel execution. In case a<br>user experiences transaction reversions, they could always direct<br>their transactions to a general sequencer (that does not use or<br>understand this extra storage layer).</p>
<ul>
<li><p>The method access boundaries could be centrally supplied&#x2F;generated<br>by the deployer.<br><br>Requirements for a contract to comply can be optional and can be<br>similar to verifying contracts - plus could be provable.<br>Contract fuzzing can be potentially utilized to find&#x2F;prove access<br>boundaries</p>
</li>
<li><p>In case the method access boundaries are found to be<br>incomplete&#x2F;wrong while execution, the sequencer would revert the<br>transaction (or) queue them to be executed sequentially. A default<br>route (not involving parallel execution) has to be maintained in<br>addition such that transaction chains involving those (incomplete)<br>contracts can be sent through the default route.<br><br>The maintained list would not be enough if the addresses it<br>interacts with, cannot be determined prior execution (delegate<br>call, arbitrary call etc)</p>
</li>
<li><p>This works for transactions that have information about all the<br>contract accounts involved in the transaction call chain. This is<br>easiest if the transaction does not involve calls to multiple<br>unknown addresses. Even one contract without information on the<br>transaction call stack could fail potential parallelizing<br>(fortunately, most of the common transactions we see in a network<br>do not involve such calls to several unknown addresses except that<br>of the senders).</p>
</li>
<li><p>Some access boundaries can have an additional spec - i.e<br>interactions with them could allow updation to the existing<br>boundaries of other methods of the contract. - for example, a<br>method that adds an ‘address’ value to the storage of the account.<br>The node that keeps track of the storage then, updates the<br>boundaries when calls are made to such methods</p>
</li>
<li><p>Some methods will not have access boundaries that can be specified -<br>in which case the external contract addresses in the boundaries<br>can be specified to be undetermined.</p>
</li>
</ul>
<p>For example, each method could have encoded access boundaries in the<br>form</p>
<p><img src="/images/struct.png"></p>
<p>Where, “Type” determines if these boundaries can be written to, and R&#x2F;W<br>determines read or write access to external contract</p>
<p>For a further simplified model, only the external contract accesses can<br>be stored for the whole contract - (similar to how comparisons are in<br>Easy parallelizability “v1” [EIP 648] )<br>for ex with-</p>
<p>tx1 &#x3D; A -&gt; B -&gt; C</p>
<p>tx2 &#x3D; E -&gt; F -&gt; D<br><br>can both be compared simply by comparing the set, and executed<br>parallelly if there&#39;s no intersection\</p>
<p>(S{A} U S{B} U S{C}) ∩ (S{E} U S{F} U S{D}) ≠ Φ</p>
<p>[Where S{X} is the method access boundaries of the method X]</p>
<h2 id="Proposal-2-Meta-AL-Transactions-and-Account-Abstraction"><a href="#Proposal-2-Meta-AL-Transactions-and-Account-Abstraction" class="headerlink" title="Proposal 2: Meta AL Transactions and Account Abstraction"></a>Proposal 2: Meta AL Transactions and Account Abstraction</h2><p>To reiterate one of the problems - people may have access to<br>eth_CreateAccessLists which generates an estimated access list for a<br>transaction (for the use in optional access list)- and conversion from<br>‘optional’ to ‘strict’ access list has been discussed before. Even with<br>access to an rpc, most of the wallets today do not support an ethereum<br>tx-type with access lists, and furthermore users might not know or want<br>to write scripts for populating transactions with the respective access<br>lists.</p>
<p>Moreover, since existing rpc methods can only give an estimation, users<br>might not be well suited to provide access lists when the requirements<br>are ‘strict’ - but at the same time specialized actors might be able to<br>provide smarter access lists. Meta transactions can be a way to relieve<br>the users from involvement with generation and supply of access lists.<br>We will start the discussion with meta-transactions (the way we know it)<br>which are suitable for specific contract addresses, and later will move<br>towards generalizing this for all contracts with ‘account abstraction’<br>methods.</p>
<p>So, to start with, access lists are a part of the tx object - and a<br>relayer can be assigned the duty to add the access lists to a<br>transaction upon forwarding a user signed message. This meta-transaction<br>can then further be sent to the actual contract. Transactions to these<br>contracts can be made cheaper - as incentivization, if they were to<br>develop and have support for Meta AL transactions. This is similar to<br>the gasless meta-transactions that some contracts are designed to<br>support. But this approach isn’t very generalized and works only for<br>contracts that opt-in and want to support parallelizability.</p>
<p>How do we generalize this? i.e allow this for all transactions<br>throughout all contracts</p>
<p>Enter - Account Abstraction</p>
<p>Account abstraction on L2 can enable forming transactions consisting of<br>multiple signers, and custom logic for validating the tx, without the<br>need for users to worry about providing access lists.<br><br>Account abstraction enables building custom transaction objects, logic,<br>signature schemes and essentially revamping the kind of<br>transaction&#x2F;operation a network supports and identifies, easily.</p>
<p>With a new userOp structure and wallet logic, any address would be able<br>to send transactions with the responsibility of providing access lists<br>to a second signer of their choice.</p>
<p>One such model that uses account-abstraction to support crowdsourced<br>(and smart) meta access-lists could be as follows-</p>
<p>Specifications:</p>
<ul>
<li><p>Abstract out signature verification and requirements with account<br>abstraction ERC-4337(modified to include provider<br>address&#x2F;signature for each user operation). A smart contract<br>wallet level abstraction with relayers could also work, but does<br>not necessarily generalize it.</p>
</li>
<li><p>There exists a market of access-list providers whose job is to<br>provide access lists for transactions. (we can call them providers<br>in short). Even with access list estimation methods available,<br>these external providers could be a step more efficient in<br>providing appropriate access lists. For instance, dapps that also<br>provide their own provider, might be a preferred choice for<br>interactions with them.<br><br>They are rated&#x2F;priced at the efficiency with which they can<br>estimate access lists for transactions (smart providers may<br>include additional parameters or have their own logic of<br>computation, such that estimation is accurate most of the times).</p>
</li>
<li><p>Based on the customized signing conditions - each user operation<br>could specify the provider for access lists (or) each account<br>could set rotating signers for supplying access lists.</p>
</li>
<li><p>A user would sign and submit a transaction to the relayer (or) an<br>operation to their wallet specifying the provider, who in turn is<br>either specified by the user, or is selected for a specific epoch</p>
</li>
<li><p>The relayer&#x2F;provider then wraps the user tx along with the relevant<br>access list for the transaction and calls the User Account. The<br>User Account can then validate the transaction, signatures and<br>send it forward for execution.<br><br><img src="/images/aa_metal.png"></p>
</li>
</ul>
<p>Account abstraction is easier to implement for a L2 than the base Layer,<br>and several L2s would move on to account abstraction at some point. If<br>this can be utilized to enable third party providers&#x2F;relayers to provide<br>‘stricter’ access lists, a new market of providers could form. This<br>probably can also be combined with ideas from ‘method access<br>boundaries’, where projects could run their own relayers&#x2F;providers that<br>could do the job of providing access lists for transactions to their<br>contracts in the most efficient way.</p>
<p>While the Quest for Scalability is never ending, there is a clock thats<br>ticking and will soon reveal a limit to how much networks can be scaled.<br>Considering the current standards, that limit would not be very high.<br>Some techniques such as these, or a combination of several, could in<br>time, be the fuel that keeps the quest for Scalability running, and<br>reset the clock, to delay the worry indefinitely for some time again in<br>the future</p>
<h2 id="So-long-and-thanks-for-all-the-fish"><a href="#So-long-and-thanks-for-all-the-fish" class="headerlink" title="So long and thanks for all the fish"></a>So long and thanks for all the fish</h2><p>But this isn’t the end of exploring the potential of the topic, the<br>intention is to start a conversation</p>
<ul>
<li><p>How efficient exactly could these methods be in practice?</p>
</li>
<li><p>How can we make parallel execution deterministic?</p>
</li>
<li><p>Several of these methods depend on existing ecosystem toolsets and<br>their compatibility. When and what kind of support will be<br>introduced in the future?</p>
</li>
<li><p>How big a change to the UX does this involve?</p>
</li>
</ul>
<p>As we wrap up for today, here are some questions that will come up over<br>and over again, and probably the only way to get the answers will be to<br>attempt implementing. Everyone of course will have different answers,<br>because it truly isn&#39;t a one-size fits all problem. But the core of the<br>matter is to acknowledge this as a nuance that can be solved, and take<br>that first step on thinking about this together, today!</p>

  </div>
</article>
<br><br>



        
          <div id="footer-post-container">
  <div id="footer-post">

    <div id="nav-footer" style="display: none">
      <ul>
        
          <li><a href="/">Home</a></li>
        
          <li><a href="/about/">About</a></li>
        
          <li><a href="/archives/">Writing</a></li>
        
          <li><a href="/search/">Search</a></li>
        
      </ul>
    </div>

    
    
      <div id="toc-footer" style="display: none">
        <ol class="toc"><li class="toc-item toc-level-5"><a class="toc-link" href="#But-here%E2%80%99s-the-thing-about-scaling-Over-time-there%E2%80%99s-always-more-demand-for-scale-than-any-one-solution-to-the-problem-can-provide-Such-is-the-tyranny-of-distributed-systems"><span class="toc-number">1.</span> <span class="toc-text">But here’s the thing about scaling. Over time, there’s always more demand for scale than any one solution to the problem can provide. Such is the tyranny of distributed systems!</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Breaking-the-Bottlenecks"><span class="toc-number"></span> <span class="toc-text">Breaking the Bottlenecks</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Amping-Up-the-EVM"><span class="toc-number"></span> <span class="toc-text">Amping Up the EVM</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Long-Run-Solutions"><span class="toc-number"></span> <span class="toc-text">Long Run Solutions</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#What-We-Can-Do-Today"><span class="toc-number"></span> <span class="toc-text">What We Can Do Today</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Discussing-Different-Approaches-to-L2-Parallelization"><span class="toc-number"></span> <span class="toc-text">Discussing Different Approaches to L2 Parallelization</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Discussion-1-Give-away-EVM-compatibility-x2F-equivalence"><span class="toc-number"></span> <span class="toc-text">Discussion:1 Give away EVM compatibility&#x2F;equivalence</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Discussion-2-Speculative-Concurrency"><span class="toc-number"></span> <span class="toc-text">Discussion 2: Speculative Concurrency</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Approximating-efficiency-of-general-speculative-concurrency-through-the-eyes-of-an-actively-operating-L2"><span class="toc-number"></span> <span class="toc-text">Approximating efficiency of general speculative concurrency through the eyes of an actively operating L2:</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Discussion-3-Parallel-execution-with-Access-Lists"><span class="toc-number"></span> <span class="toc-text">Discussion 3: Parallel execution with Access Lists</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#What-if-wallets-add-support-for-the-tx-type-How-do-we-still-go-from-%E2%80%98optional%E2%80%99-to-%E2%80%98strict%E2%80%99-access-lists-and-enable-parallelization-on-L2"><span class="toc-number"></span> <span class="toc-text">What if wallets add support for the tx-type? How do we still go from ‘optional’ to ‘strict’ access lists and enable parallelization on L2?</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Two-Proposals"><span class="toc-number"></span> <span class="toc-text">Two Proposals:</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Proposal-1-Method-Access-Boundaries"><span class="toc-number"></span> <span class="toc-text">Proposal 1: Method Access Boundaries</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Proposal-2-Meta-AL-Transactions-and-Account-Abstraction"><span class="toc-number"></span> <span class="toc-text">Proposal 2: Meta AL Transactions and Account Abstraction</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#So-long-and-thanks-for-all-the-fish"><span class="toc-number"></span> <span class="toc-text">So long and thanks for all the fish</span></a>
      </div>
    

    <div id="share-footer" style="display: none">
      <ul>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.facebook.com/sharer.php?u=http://example.com/2022/09/28/parallel-exec/"><i class="fab fa-facebook fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://twitter.com/share?url=http://example.com/2022/09/28/parallel-exec/&text=Parallel Execution of Transaction in the EVM: Scaling L2s even further"><i class="fab fa-twitter fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.linkedin.com/shareArticle?url=http://example.com/2022/09/28/parallel-exec/&title=Parallel Execution of Transaction in the EVM: Scaling L2s even further"><i class="fab fa-linkedin fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://pinterest.com/pin/create/bookmarklet/?url=http://example.com/2022/09/28/parallel-exec/&is_video=false&description=Parallel Execution of Transaction in the EVM: Scaling L2s even further"><i class="fab fa-pinterest fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="mailto:?subject=Parallel Execution of Transaction in the EVM: Scaling L2s even further&body=Check out this article: http://example.com/2022/09/28/parallel-exec/"><i class="fa-solid fa-envelope fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://getpocket.com/save?url=http://example.com/2022/09/28/parallel-exec/&title=Parallel Execution of Transaction in the EVM: Scaling L2s even further"><i class="fab fa-get-pocket fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://reddit.com/submit?url=http://example.com/2022/09/28/parallel-exec/&title=Parallel Execution of Transaction in the EVM: Scaling L2s even further"><i class="fab fa-reddit fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.stumbleupon.com/submit?url=http://example.com/2022/09/28/parallel-exec/&title=Parallel Execution of Transaction in the EVM: Scaling L2s even further"><i class="fab fa-stumbleupon fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://digg.com/submit?url=http://example.com/2022/09/28/parallel-exec/&title=Parallel Execution of Transaction in the EVM: Scaling L2s even further"><i class="fab fa-digg fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.tumblr.com/share/link?url=http://example.com/2022/09/28/parallel-exec/&name=Parallel Execution of Transaction in the EVM: Scaling L2s even further&description="><i class="fab fa-tumblr fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://news.ycombinator.com/submitlink?u=http://example.com/2022/09/28/parallel-exec/&t=Parallel Execution of Transaction in the EVM: Scaling L2s even further"><i class="fab fa-hacker-news fa-lg" aria-hidden="true"></i></a></li>
</ul>

    </div>

    <div id="actions-footer">
        <a id="menu" class="icon" href="#" onclick="$('#nav-footer').toggle();return false;"><i class="fa-solid fa-bars fa-lg" aria-hidden="true"></i> Menu</a>
        
          <a id="toc" class="icon" href="#" onclick="$('#toc-footer').toggle();return false;"><i class="fa-solid fa-list fa-lg" aria-hidden="true"></i> TOC</a>
        
        <a id="share" class="icon" href="#" onclick="$('#share-footer').toggle();return false;"><i class="fa-solid fa-share-alt fa-lg" aria-hidden="true"></i> Share</a>
        <a id="top" style="display:none" class="icon" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');"><i class="fa-solid fa-chevron-up fa-lg" aria-hidden="true"></i> Top</a>
    </div>

  </div>
</div>

        
        <footer id="footer">
  <div class="footer-left">
    Copyright &copy;
    
    
    2019-2023
    Souradeep Das
  </div>
  <div class="footer-right">
    <nav>
      <ul>
        <!--
       --><li><a href="/">Home</a></li><!--
     --><!--
       --><li><a href="/about/">About</a></li><!--
     --><!--
       --><li><a href="/archives/">Writing</a></li><!--
     --><!--
       --><li><a href="/search/">Search</a></li><!--
     -->
      </ul>
    </nav>
  </div>
</footer>

    </div>
    <!-- styles -->



  <link rel="preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css" crossorigin="anonymous" onload="this.onload=null;this.rel='stylesheet'"/>


    <!-- jquery -->

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js" crossorigin="anonymous"></script>




<!-- clipboard -->

  
    <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.7/clipboard.min.js" crossorigin="anonymous"></script>
  
  <script type="text/javascript">
  $(function() {
    // copy-btn HTML
    var btn = "<span class=\"btn-copy tooltipped tooltipped-sw\" aria-label=\"Copy to clipboard!\">";
    btn += '<i class="fa-regular fa-clone"></i>';
    btn += '</span>';
    // mount it!
    $(".highlight table").before(btn);
    var clip = new ClipboardJS('.btn-copy', {
      text: function(trigger) {
        return Array.from(trigger.nextElementSibling.querySelectorAll('.code')).reduce((str,it)=>str+it.innerText+'\n','')
      }
    });
    clip.on('success', function(e) {
      e.trigger.setAttribute('aria-label', "Copied!");
      e.clearSelection();
    })
  })
  </script>


<script src="/js/main.js"></script>

<!-- search -->

<!-- Baidu Analytics -->

<!-- Cloudflare Analytics -->

<!-- Disqus Comments -->

<!-- utterances Comments -->

</body>
</html>
