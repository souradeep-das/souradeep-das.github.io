<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>Deploying Uniswap V3: A developers guide to Navigating the Complexities</title>
      <link href="/2023/05/06/uni-v3/"/>
      <url>/2023/05/06/uni-v3/</url>
      
        <content type="html"><![CDATA[<!-- # **Deploying Uniswap V3:** <br>*A developers guide to Navigating the Complexities* --><p>After much thoughtful contemplation, the diligent unicorn has finally decided to reach for newer pastures. All of this, of-course, happened with the passing of proposal <a href="https://gov.uniswap.org/t/deploy-uniswap-v3-to-boba-network/18018">#18018</a>, the community has now decided to launch Uniswap V3 to the Boba Network L2 on Ethereum! As of the current stance, the Uniswap community has been actively voting to deploy V3 on several other chains too, and with the license expiry this April- we may expect several other V3 forks to come up soon.</p><p>The primary step to Deploying Uniswap V3 (or for that matter a clone) is to deploy the smart contracts that make up this amazing V3 protocol, and that’s exactly what we will be covering in this article. </p><p>Before we begin, the Uniswap team deserves a huge shout out for assimilating all the associated content in an organized unified location.<br><a href="https://github.com/Uniswap/v3-new-chain-deployments">V3 new chain repo</a><br><a href="https://github.com/Uniswap/deploy-v3">V3 deploy repo</a></p><p>These repositories serve their purpose very well and we(and you) will be using these throughout the article. However, despite their best efforts (and at no fault of theirs), the deployment process might include several intricacies, primarily associated with carrying out the steps on a chain other than Ethereum. While it is not possible, and probably unfair to ask to list out all these intricacies or extra details, this article stands to serve the exact purpose and complement the repos by filling in as many information gaps to make your deployment experience a breeze!</p><p><em>As an added note: the uniswap repos are a work in progress. Look out for the github “commits” mentioned to get the most consistent results from this article</em></p><h2>Accio with the unicorn core  (or) how to deploy the core v3 contracts?</h2><p>Get the “<a href="https://github.com/Uniswap/deploy-v3">v3-deploy repo</a>“ and clone it into your local system<br>Commit: <code>b7aac0f</code></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ git clone https://github.com/Uniswap/deploy-v3.git</span><br><span class="line">$ cd deploy-v3</span><br><span class="line">$ yarn &amp;&amp; yarn build</span><br></pre></td></tr></table></figure><p>This repo collects almost all of the contracts that make up the v3 protocol, and additionally provides scripts to deploy them easily, all in a single command. But wait, however appealing that command might be to run now, lets first make sure we have everything necessary and in place.</p><p>The command would require the following arguments:-</p><p><strong>Private key</strong> - an account that has funds to deploy the contracts, this account will not have any privileges on the contract</p><p><strong>Json prc</strong> - the json rpc url of the network where you will deploy</p><p><strong>Weth9 address</strong> - address of the WETH9 contract on the specific chain where you are deploying</p><p><strong>Native currency label</strong> - the native token symbol (ETH)</p><p><strong>Owner address</strong> - ??</p><p><strong>Confirmations</strong> - the no of confirmations to wait before each transaction (if you are using a L2 with instant soft finality, select:  “0”)</p><p>(there are some other optional arguments - state, v2coreFactory and gasPrice, which you don’t have to worry about unless you know what you are doing)</p><p><u>What about the Owner address?</u></p><p>The owner address that you will use here, will specifically control the following on your deployed contracts-<br>a) UniswapV3Factory contracts owner privileges that allow control over pool protocol fees<br>b) The ownership of the proxy contract for NonfungibleTokenPositionDescriptor</p><p>The address you select here will depend on what you want to do for the deployments</p><p>Do you want to centrally control the parameters for your deployment? <em>Choose an address that you deem to be the admin</em></p><p>Do you have a DAO that should control the parameters? <em>Chose the DAO address to be the owner (for most cases of compound like DAOs, this is the Timelock contract)</em></p><p>Do you want the Uniswap DAO (or a DAO on a different layer) to control the parameters? In case you are deploying Uniswap to a new chain, as was the case for Boba - here’s what you need to do. </p><h3>Ownership across layers</h3><p>In order for the Uniswap DAO on Ethereum to assume ownership of your contracts that are on a different chain, you will have to use some form of messaging system. In the case of several L2s and rollups, there exists a default message passing system that enables taking data from L1&gt;L2.</p><p>In case of Boba&#x2F;Optimism or the likes this is the crossDomainMessenger which enables message passing, while in the core it is the enqueue() feature that allows users to trigger transaction on L2 by enqueueing transactions on L1 </p><p><font color="green"> Caution: The following contract works only for protocols that use the Optimism messaging system, furthermore comments in green signify commands for Boba Network</p><p>For this we use a contract on L2 that forwards messages from an L1 address, in other words - any L2 contract that has the following contract set as an owner, (or another privilege) will ultimately be owned by the <code>l1Owner</code> address on the ‘root’ chain (here, ethereum)<br></font></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line">pragma solidity 0.7.6;</span><br><span class="line"></span><br><span class="line">interface Messenger &#123;</span><br><span class="line">    function sendMessage(address _target, bytes memory _message, uint32 _gasLimit) external;</span><br><span class="line"></span><br><span class="line">    function relayMessage(</span><br><span class="line">        address _target,</span><br><span class="line">        address _sender,</span><br><span class="line">        bytes memory _message,</span><br><span class="line">        uint256 _messageNonce</span><br><span class="line">    ) external;</span><br><span class="line"></span><br><span class="line">    function xDomainMessageSender() external view returns (address);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">// L2 Contract which receives messages from a specific L1 address and transparently</span><br><span class="line">// forwards them to the destination.</span><br><span class="line">// </span><br><span class="line">// Any other L2 contract which uses this contract&#x27;s address as a privileged position,</span><br><span class="line">// can be considered to be owned by the `l1Owner`</span><br><span class="line">contract CrossChainAccount &#123;</span><br><span class="line">    Messenger messenger;</span><br><span class="line">    address l1Owner;</span><br><span class="line"></span><br><span class="line">    constructor(Messenger _messenger, address _l1Owner) &#123;</span><br><span class="line">        messenger = _messenger;</span><br><span class="line">        l1Owner = _l1Owner;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    // `forward` `calls` the `target` with `data`, </span><br><span class="line">    // can only be called by the `messenger`</span><br><span class="line">    // can only be called if `tx.l1MessageSender == l1Owner`</span><br><span class="line">    function forward(address target, bytes memory data) external &#123;</span><br><span class="line">        // 1. The call MUST come from the L1 Messenger</span><br><span class="line">        require(msg.sender == address(messenger), &quot;Sender is not the messenger&quot;);</span><br><span class="line">        // 2. The L1 Messenger&#x27;s caller MUST be the L1 Owner</span><br><span class="line">        require(messenger.xDomainMessageSender() == l1Owner, &quot;L1Sender is not the L1Owner&quot;);</span><br><span class="line">        // 3. Make the external call</span><br><span class="line">        (bool success, bytes memory res) = target.call(data);</span><br><span class="line">        require(success, string(abi.encode(&quot;XChain call failed:&quot;, res)));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><font color="green"> The contract takes two parameters -<br><strong>_messenger</strong> &#x3D; the messenger on L2 (L2CrossDomainMessenger for Boba)<br><strong>_l1Owner</strong> &#x3D; the address on L1 which actually holds ownership of any privilege the contract above has (Uniswap Timelock contract on L1 for Boba)</p><p>For Boba, this is the contract that is deployed and has been given the ownership of the core uniswap contracts<br></font></p><p><br><br></p><p>Now that we have figured out what the Owner address should be, let’s continue with the deployment!</p><p>Thanks to the script just run the following with your own arguments on your local clone of “v3-deploy” -</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ yarn start -pk &lt;enter-private-key&gt; -j &lt;your-rpc-endpoint&gt; -w9 &lt;weth-address&gt; -ncl &lt;native token label&gt; -o &lt;owner-address-we-decided-upon&gt; -c &lt;no-of-block-confirmations&gt;</span><br></pre></td></tr></table></figure><p><font color="green"> For eg, the command to deploy Uniswap-v3 on Boba </font></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ yarn start -pk &lt;redacted&gt; -j https://mainnet.boba.network -w9 0xDeadDeAddeAddEAddeadDEaDDEAdDeaDDeAD0000 -ncl ETH -o 0x53163235746CeB81Da32293bb0932e1A599256B4 -c 0</span><br></pre></td></tr></table></figure><p>You will see the contracts being deployed (and some ownership being transferred). And, when all the steps are done - you would also notice a state.json file which holds the deployed addresses. </p><p>If the deployment fails in between, rerunning the command will use the state.json file and resume the deployment process from where you stopped.</p><p>Known issue - If during a deployment run, the process fails after step 11 i.e “UniswapV3Factory ownership set” - a subsequent run may fail - because adding a new fee tier (step 2) from the script expects the owner of UniswapV3Factory to be the deployer. In this case - try modifying the script to ignore step 2, or start a fresh deployment by deleting state.json</p><h3>Verifying the contracts on Etherscan</h3><p>In order to verify these contracts, we will have to revert back to the repositories in which these contracts actually live.</p><p>Just open a new window, and clone all of these repositories</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ git clone https://github.com/Uniswap/v3-core &amp;&amp; git clone https://github.com/Uniswap/v3-periphery.git &amp;&amp; git clone https://github.com/Uniswap/v3-staker.git &amp;&amp; git clone https://github.com/Uniswap/swap-router-contracts.git</span><br></pre></td></tr></table></figure><p>We will use the @nomiclabs&#x2F;hardhat-etherscan plugin to verify which all these repos already have set up, so you won’t have to do a thing as long as hardhat-etherscan supports the network on which you are deploying</p><p><u>What if hardhat-etherscan doesn’t natively support the network?</u></p><p>The plugin fortunately allows adding custom networks for verification. (if it does not hardhat-etherscan is probably on an older version, update it to (^3.1.6)<br>Update it to the latest with</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ npm remove @nomiclabs/hardhat-etherscan</span><br><span class="line">$ npm install --save-dev @nomiclabs/hardhat-etherscan</span><br></pre></td></tr></table></figure><p>To enable your custom chain with the hardhat-etherscan plugin, add the network to the list, and a custom chain field to etherscan like the following: (and do this for all the repos we have cloned)</p><p><font color="green"> For eg, on Boba the config should look like- </font></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">networks: &#123;</span><br><span class="line">   hardhat: &#123;</span><br><span class="line">     allowUnlimitedContractSize: false,</span><br><span class="line">   &#125;,</span><br><span class="line">   mainnet: &#123;</span><br><span class="line">     url: `https://mainnet.infura.io/v3/$&#123;process.env.INFURA_API_KEY&#125;`,</span><br><span class="line">   &#125;,</span><br><span class="line">   ...</span><br><span class="line">   ...</span><br><span class="line">   &#x27;boba-mainnet&#x27;: &#123;</span><br><span class="line">     url: &#x27;https://mainnet.boba.network&#x27;,</span><br><span class="line">   &#125;,</span><br><span class="line"> &#125;,</span><br><span class="line"> etherscan: &#123;</span><br><span class="line">   // Your API key for Etherscan</span><br><span class="line">   // Obtain one at https://etherscan.io/</span><br><span class="line">   apiKey: &#123;</span><br><span class="line">     &#x27;boba-mainnet&#x27;: &#x27;&lt;enter-etherscan-api-key&gt;&#x27;,</span><br><span class="line">   &#125;,</span><br><span class="line">   customChains: [</span><br><span class="line">     &#123;</span><br><span class="line">       network: &#x27;boba-mainnet&#x27;,</span><br><span class="line">       chainId: 288,</span><br><span class="line">       urls: &#123;</span><br><span class="line">         apiURL: &#x27;https://api.bobascan.com/api&#x27;,</span><br><span class="line">         browserURL: &#x27;https://bobascan.com&#x27;,</span><br><span class="line">       &#125;,</span><br><span class="line">     &#125;,</span><br><span class="line">   ]</span><br><span class="line"> &#125;,</span><br><span class="line"> ...</span><br><span class="line"> ...</span><br><span class="line"></span><br></pre></td></tr></table></figure><p><br><br></p><p>Now that hardhat-etherscan is ready, in case it wasn’t, let’s use it to verify the contracts we just deployed.</p><p>All the contracts are distributed among the four repos, and a key is given below:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">v3-core: UniswapV3Factory.sol, </span><br><span class="line">v3-periphery: UniswapInterfaceMulticall.sol, TickLens.sol, NFTDescriptor.sol, NonfungibleTokenPositionDescriptor.sol*, NonfungiblePositionManager*, V3Migrator*</span><br><span class="line">v3-staker: UniswapV3Staker.sol*, </span><br><span class="line">swap-router-contracts: QuoterV2.sol*, SwapRouter02.sol*</span><br></pre></td></tr></table></figure><p>For each of these verify the contracts by running the following command on the respective repositories:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ npx hardhat verify --network &lt;network-name&gt; &lt;deployed-contract-address&gt;</span><br></pre></td></tr></table></figure><p><font color="green"> For eg, verifying the UniswapV3Factory on Boba (use your own address)</font></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ npx hardhat verify --network boba-mainnet 0xFFCd7Aed9C627E82A765c3247d562239507f6f1B</span><br></pre></td></tr></table></figure><p>For some of these contracts (indicated with a * ) you would also need to provide the constructor arguments for verification</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ npx hardhat verify --network &lt;network-name&gt; &lt;deployed-contract-address&gt; &lt;constructor-arg-1&gt; &lt;constructor-arg-2&gt; …</span><br></pre></td></tr></table></figure><p><font color="green"> For eg, verifying the NonfungibleTokenPositionDescriptor on Boba (use your own address) </font></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ npx hardhat verify --network boba-mainnet 0xb6751A274EDAe02A911E3bB23682FAaF380433b7 &quot;0xDeadDeAddeAddEAddeadDEaDDEAdDeaDDeAD0000&quot; &quot;0x0000000000000000000000000000000000000000000000000000000000455448&quot;</span><br></pre></td></tr></table></figure><p><font color="green">And verifying the UniswapV3Staker on Boba </font></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npx hardhat verify --network boba-mainnet 0x6a6c1198f85B084822138DFd3fA9686e4029c091 &quot;0xFFCd7Aed9C627E82A765c3247d562239507f6f1B&quot; &quot;0x0bfc9aC7E52f38EAA6dC8d10942478f695C6Cf71&quot; &quot;2592000&quot; &quot;1892160000&quot;</span><br></pre></td></tr></table></figure><p>That’s it! You should now have a set of uniswap v3 contracts deployed, verified and ready to take on all those transactions. Give yourself a pat in the back, take a deep breath, think happy thoughts, and let’s slay that final challenge!</p><p><br><br></p><h2>Deploying the Universal Router</h2><p>The Universal Router is something that you might or might not need, depending on your use case for the contracts. <a href="https://blog.uniswap.org/permit2-and-universal-router">The Universal Router is a fairly new addition</a> to Uniswap, which allows optimizing trades across multiple token types, and the “interfaces” have been moving forwards to utilizing it!</p><p>This is where the Universal Router lives: <a href="https://github.com/Uniswap/universal-router">https://github.com/Uniswap/universal-router</a><br>Commit: <code>f0e15fe</code></p><p>Clone the repo along with its submodules and build it</p><p><font color="red">WARNING:</font> make sure you have commit <code>f0e15fe</code> or later (latest). The older version with json parameters support, includes an error where constructor arguments are offset by 2, and will result in an incorrect deployment</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ git clone --recurse-submodules https://github.com/Uniswap/universal-router.git</span><br><span class="line">$ cd universal-router</span><br><span class="line">$ yarn &amp;&amp; yarn compile</span><br></pre></td></tr></table></figure><p>Install Forge if you do not have it installed, follow the installation docs here: <a href="https://github.com/foundry-rs/foundry">https://github.com/foundry-rs/foundry</a></p><p>Now that we have cloned the repo locally, like we have practiced - let’s take a moment and make sure we have everything we need in order to proceed</p><p>This deployment process includes the deployment of three contracts, namely-<br>i) UniversalRouter<br>ii) UnsupportedProtocol<br>iii) Permit2</p><p>And, these are the parameters the Universal Router works with and we will have to specify</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">           permit2, </span><br><span class="line">           weth9,</span><br><span class="line">           seaport,</span><br><span class="line">           seaportV1_4,</span><br><span class="line">           openseaConduit,</span><br><span class="line">           nftxZap,</span><br><span class="line">           x2y2,</span><br><span class="line">           foundation,</span><br><span class="line">           sudoswap,</span><br><span class="line">           elementMarket,</span><br><span class="line">           nft20Zap,</span><br><span class="line">           cryptopunks,</span><br><span class="line">           looksRare,</span><br><span class="line">           routerRewardsDistributor,</span><br><span class="line">           looksRareRewardsDistributor,</span><br><span class="line">           looksRareToken,</span><br><span class="line">           v2Factory,</span><br><span class="line">           v3Factory,</span><br><span class="line">           pairInitCodeHash,</span><br><span class="line">           poolInitCodeHash,</span><br><span class="line">           paymentRecipient,</span><br><span class="line">           paymentAmountBips,</span><br><span class="line">unsupported</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3>The curious case of Permit2 and Deterministic Deployments</h3><p>Of the three contracts, Permit2 is deployed using CREATE2 (deterministic deployment) to have the same address across chains.</p><p>If your chain does not enforce strict replay protection you could safely skip this section!</p><p>The most common Deterministic Deployment contract is <a href="https://github.com/Arachnid/deterministic-deployment-proxy">https://github.com/Arachnid/deterministic-deployment-proxy</a>, and this is also what forge uses when you will run the script. It uses a novel method called - Nick’s method, which works with a pre-signed deployment tx (without chainId) to deploy the Deterministic Deployment Proxy to the same address “0x4e59b44847b379578588920ca78fbf26c0b4956c” on all chains. (and this proxy further allows for deterministic deployments through CREATE2)</p><p>However, some EVM chains have strict replay protection enabled (<a href="https://eips.ethereum.org/EIPS/eip-155">EIP-155</a>), in other words they do not allow submitting transaction without a chainId, (which is what the deployment of the Deterministic Deployment will demand), as is the case for Boba Network.</p><p>Now, depending on the level where replay protection is enabled on the chain, there may still be ways to make the pre-signed tx work, and there’s and if it’s possible there’s a good chance that you will find the contract already deployed on the address “0x4e59b44847b379578588920ca78fbf26c0b4956c” for the chain.</p><p>(For ex, Avax has replay protection on the json-rpc level, so spinning up a node without it enabled, allows to deploy the proxy)</p><p>If we are still without the deterministic deployment proxy, the next best option probably is to use an alternative.<br>Gnosis Safes are some other contracts which require Deterministic Deployment, and demand consistency across all chains. As a result, the Gnosis team were quick to identify, and maintain a deterministic deployment factory (for EIP155 enabled chains) that, if deployed and used on most chains, would produce similar deterministic contract deployments. <a href="https://github.com/safe-global/safe-singleton-factory">https://github.com/safe-global/safe-singleton-factory</a></p><p>Find if a safe singleton factory exists on the chain, as an alternative for the deterministic deployment of Permit2</p><p>To deploy the Permit2 using the deterministic deployment proxy, you will need to send a tx to the deployment proxy, with data &#x3D; encoded(salt, depl_code)</p><p>Here’s a script that can enable you to submit such a tx<br><a href="https://gist.github.com/souradeep-das/a30fd91296741234d11fabc5b06b9a72">https://gist.github.com/souradeep-das/a30fd91296741234d11fabc5b06b9a72</a></p><p><br><br></p><p>Alright, let’s return back to the parameters we took a look at before:</p><p><em>permit2</em>: set it to address(0) if you have the deterministic deployment proxy at “0x4e59b44847b379578588920ca78fbf26c0b4956c” and want the script to deploy it for you (or) if you do not - refer to the previous section and deploy the Permit2 using the alt proxy</p><p><em>weth9</em>: set to the WETH9 address on the chain</p><p><em>v3Factory</em>: set to the UniswapV3Factory that was deployed as a part of the core v3 deployment</p><p><em>poolInitCodeHash</em>: set to “0xe34f199b19b2b4f47f68442619d555527d244f78a3297ea89325f843f87b8b54” according to the value on your PoolAddress.sol contract (from the core deployments)</p><p><em>pairInitCodeHash</em>: set to BYTES32_ZERO if UniswapV2 is not supported</p><p><em>unsupported</em>: set to address(0) if you want this to be deployed along with the script</p><p>All the remaining parameters need to be set to address(0) or <strong>UNSUPPORTED_PROTOCOL</strong>, or 0 values</p><p>Create a new file under script&#x2F;deployParameters - <code>DeployNetwork.s.sol</code> and add in the appropriate parameters. Use DeployGoerli.s.sol as reference (you will have to replace the parameters and the contract name)</p><p>Assuming you have now put the required parameters in a file called <code>DeployNetwork.s.sol</code>, the command to deploy is:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ forge script --broadcast --rpc-url &lt;rpc-url&gt; --private-key &lt;your-private-key&gt; --sig &#x27;run()&#x27; script/deployParameters/DeployNetwork.s.sol:DeployNetwork</span><br></pre></td></tr></table></figure><p>If your chain is among the supported networks for forge verification, you could also verify the contracts with the deployment by adding the following three flags</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ forge script --broadcast --rpc-url &lt;rpc-url&gt; --private-key &lt;your-private-key&gt; --sig &#x27;run()&#x27; script/deployParameters/DeployNetwork.s.sol:DeployNetwork --chain-id &lt;chain-id-network&gt; --etherscan-api-key &lt;etherscan-api-key&gt; --verify</span><br></pre></td></tr></table></figure><p><u>Fixing common errors</u></p><p>Error:<br><font color="red">Failed to get EIP-1559 fees</font></p><p>This means the chain you are trying to deploy doesn’t support EIP-1559, in which case deploy with the following flag added</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ forge script --broadcast --rpc-url &lt;rpc-url&gt; --private-key &lt;your-private-key&gt; --sig &#x27;run()&#x27; script/deployParameters/DeployNetwork.s.sol:DeployNetwork --chain-id &lt;chain-id-network&gt; --etherscan-api-key &lt;etherscan-api-key&gt; --verify --legacy</span><br></pre></td></tr></table></figure><p>Error:<br><font color="red">Nonce already used</font></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ forge script --broadcast --rpc-url &lt;rpc-url&gt; --private-key &lt;your-private-key&gt; --sig &#x27;run()&#x27; script/deployParameters/DeployNetwork.s.sol:DeployNetwork --chain-id &lt;chain-id-network&gt; --etherscan-api-key &lt;etherscan-api-key&gt; --verify --legacy --slow</span><br></pre></td></tr></table></figure><p>Once your contracts are deployed, make sure the arguments used were what you intended to use, and the protocols unsupported are set to the deployed unsupportedProtocol contract address. Refer to the generate file - latest.json under broadcast&#x2F; for the deployment info.</p><h3>Verifying the contracts for other non-supported chains</h3><p>To verify the UnsupportedProtocol and Universal Router contracts, make sure you are on the universal-router repo, and run the following:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ forge verify-contract &lt;unsupported-protocol-address&gt; contracts/deploy/UnsupportedProtocol.sol:UnsupportedProtocol --verifier-url &lt;etherscan-api-url&gt; --compiler-version &quot;v0.8.17+commit.8df45f5f&quot; --optimizer-runs 1000000 --chain-id &lt;chain-id&gt; --watch</span><br></pre></td></tr></table></figure><p>And </p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ forge verify-contract &lt;universal-router-address&gt; contracts/UniversalRouter.sol:UniversalRouter --constructor-args &lt;encoded-constructor-args&gt; --verifier-url &lt;etherscan-api-url&gt; --compiler-version &quot;v0.8.17+commit.8df45f5f&quot; --optimizer-runs 1000000 --chain-id &lt;chain-id&gt; --watch</span><br></pre></td></tr></table></figure><p>One way to obtain the encoded constructor args is to use cast from foundry</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ cast abi.encode &quot;constructor(address,address,address,address,address,address,address,address,address,address,address,address,address,address,address,address,address,address,bytes32,bytes32,address,uint256)&quot; &lt;arg-1&gt; &lt;arg-2&gt; ….. &lt;arg-22&gt;</span><br></pre></td></tr></table></figure><p><font color="green">For eg, on Boba</font></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ forge verify-contract 0x020A39620A5af7Ff456B2523C35fc8B897E9071a contracts/deploy/UnsupportedProtocol.sol:UnsupportedProtocol --verifier-url https://api.bobascan.com/api --compiler-version &quot;v0.8.17+commit.8df45f5f&quot; --optimizer-runs 1000000 --chain-id 288 --watch</span><br></pre></td></tr></table></figure><p><br><br></p><p>To verify permit2, grab the permit2 repo here <a href="https://github.com/Uniswap/permit2">https://github.com/Uniswap/permit2</a></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ git clone https://github.com/Uniswap/permit2.git</span><br><span class="line">$ cd permit2</span><br><span class="line">$ forge install</span><br></pre></td></tr></table></figure><p>Now set <code>ETHERSCAN_API_KEY</code> as an env var<br>And then proceed to verify with</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ forge verify-contract &lt;permit2-contract-address&gt; src/Permit2.sol:Permit2 --verifier-url &lt;etherscan-api-url&gt; --compiler-version &quot;v0.8.17+commit.8df45f5f&quot; --optimizer-runs 1000000 --chain-id &lt;chain-id-of-network&gt; --watch</span><br></pre></td></tr></table></figure><p><font color="green">For eg, on Boba</font></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ forge verify-contract 0xF80c91442D3EF66632958C0d395667075FC82fB0 src/Permit2.sol:Permit2 --verifier-url https://api.bobascan.com/api --compiler-version &quot;v0.8.17+commit.8df45f5f&quot; --optimizer-runs 1000000 --chain-id 288 --watch</span><br></pre></td></tr></table></figure><p><br><br></p><p>Congratulations! With all of that done, you now have a deployed set of Uniswap V3 contracts at your disposal, plus a universal router to go with it, in case you need one.<br>Cheers, and Goodbye for now!</p><p><img src="https://i.imgur.com/rXjX3wa.jpg"></p>]]></content>
      
      
      
        <tags>
            
            <tag> Rollup </tag>
            
            <tag> Layer 2 </tag>
            
            <tag> Defi </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Parallel Execution of Transaction in the EVM: Scaling L2s even further</title>
      <link href="/2022/09/28/parallel-exec/"/>
      <url>/2022/09/28/parallel-exec/</url>
      
        <content type="html"><![CDATA[<p>As developers working with Ethereum, we all know that the Ethereum Layer1 (L1) isn’t very scalable, and that’s what Layer 2 (L2) projects like Boba, Optimism, zkSync etc are committed to address and resolve in their own way.</p><p>Of course, there are several approaches to scaling - on-chain approaches like Sharding parallelizes execution by splitting the network into multiple shards. And the L2 approach takes transaction execution off-chain, using the L1 as a settlement layer through rollups or other techniques.</p><h5 id="But-here’s-the-thing-about-scaling-Over-time-there’s-always-more-demand-for-scale-than-any-one-solution-to-the-problem-can-provide-Such-is-the-tyranny-of-distributed-systems"><a href="#But-here’s-the-thing-about-scaling-Over-time-there’s-always-more-demand-for-scale-than-any-one-solution-to-the-problem-can-provide-Such-is-the-tyranny-of-distributed-systems" class="headerlink" title="But here’s the thing about scaling. Over time, there’s always more demand for scale than any one solution to the problem can provide. Such is the tyranny of distributed systems!"></a>But here’s the thing about scaling. Over time, there’s always more demand for scale than any one solution to the problem can provide. Such is the tyranny of distributed systems!</h5><p>That means a L2’s job is never done, or in general any solution for scalability is not truly complete. As is the case, the community is always looking for better ways to increase throughput and reduce latency to meet the ever-increasing demand of projects spanning the internet that need transaction finality across many organizations without sacrificing performance or reliability.</p><p>In this article we are going to get into some approaches that could push the boundaries of scalability even further, including some new methods that can be considered - specifically addressed around a single bottleneck. We will also try and weigh the pros and cons of each, to identify the most promising path forward.</p><h2 id="Breaking-the-Bottlenecks"><a href="#Breaking-the-Bottlenecks" class="headerlink" title="Breaking the Bottlenecks"></a>Breaking the Bottlenecks</h2><p>Scaling one part of a system without scaling the bottlenecks around it doesn’t get you far. While some of the more prominent reasons that limit scalability are consensus and propagation of messages (in turn the block size and time), the Ethereum Virtual Machine (EVM) is itself, in its core, a crucial limiter of scale. And, since several L2s would still want to utilize and maintain EVM compatibility&#x2F;equivalence to replicate L1 user experience - they also inherently need to, and are more suitable for finding ways to get around this bottleneck.<br>So the natural question is - what exactly is this bottleneck and how do we get around this?</p><h2 id="Amping-Up-the-EVM"><a href="#Amping-Up-the-EVM" class="headerlink" title="Amping Up the EVM"></a>Amping Up the EVM</h2><p>Y(S, T)&#x3D; S&#39;</p><p>Ethereum is a state machine, and the EVM executes transactions sequentially, one by one. It doesn’t execute other transactions until the execution of the current transaction is completed and the resulting state is computed. This is to avoid state&#x2F;storage collisions and preserve atomicity of transactions. In other words, this ensures that each transaction is a self-contained, atomic unit of operation that changes the system’s state without interference from or interference to any other concurrent transactions. The execution, however, is still sequential, even with a set of completely independent transactions, because the EVM isn’t designed to be able to execute them at the same time.</p><p><img src="/images/giphy.gif" alt="Sequential Tx"></p><p>Despite this being a fundamental feature, it remains a bottleneck for the performance of the network and can limit the throughput of Ethereum or any EVM chain.<br>Especially for an L2 where other limitations to scalability like consensus(and message propagation) might not exist, serial execution can turn out to be a more pronounced limitation. Additionally, the L2 as an execution layer for the L1, could be an easier and more suitable ground for implementing approaches to go around the bottleneck and scale maximally.</p><p>This brings in the need for parallel execution of transactions, and more so, in an L2 context.</p><p>We can think of parallel execution to be possible at two levels:</p><ol><li><p>Parallel at the transaction level - treat each transaction as the smallest unit for parallelization and execute them on multiple threads.</p></li><li><p>Parallel at the opcode level - treat each operation as the smallest unit and parallelize opcodes, memory access, etc for multiple transactions.</p></li></ol><p>While parallelizing at the transaction level is relatively straightforward and could produce considerable throughput improvements, parallelizing at the opcode level will attain maximum scalability. However, the latter approach is inherently more complex. We will focus on the first approach to begin with, and discuss it throughout the rest of the article.</p><h2 id="Long-Run-Solutions"><a href="#Long-Run-Solutions" class="headerlink" title="Long Run Solutions"></a>Long Run Solutions</h2><p>If we further narrow it down, storage access is where the EVM spends most time while executing a transaction. And when executed sequentially, it represents a significant portion of the overall execution time. Optimizing storage access, hence, could be an important step in enabling parallel execution.<br>At the same time, much of Ethereum’s ongoing research efforts have been on statelessness, witnesses, and light clients, which could enable pre-fetching or optimizing storage accesses. Furthermore, Sharding would split the network into multiple smaller networks (shards), and would theoretically parallelize execution with the design. Things would be easier for the L1, with all of these implemented in the future.</p><h2 id="What-We-Can-Do-Today"><a href="#What-We-Can-Do-Today" class="headerlink" title="What We Can Do Today"></a>What We Can Do Today</h2><p>Until these future enhancements arrive, there are ways to address parallel execution that can be made practical today.</p><p>Here are a few, of the numerous approaches people have thought about achieving concurrency:</p><p>a)  UTXO based blockchain - This is much easier because a UTXO spending<br>    transaction has the unspent outputs (which are also signed) as<br>    inputs for every transaction, and that makes it easy to identify<br>    the storage slots that are going to be affected.</p><p>b)  Speculative concurrency - Attempt executing every transaction in<br>    parallel, transactions with conflicts are scheduled at the end.</p><p>c)  Speculative concurrency with role-based separation of nodes - Some<br>    nodes participate in ordering (e.g., grouping transactions<br>    together) and some execute.</p><p>d)  Storage access lists provided as an input for transactions - To help<br>    identify what storage (or which contracts) the transaction will<br>    access.</p><p>e)  Predicting access lists or speculatively generating and caching<br>    (e.g., estimateGas).</p><p>f)  Static analysis of contracts or bytecode analysis to determine<br>    access lists ( e.g., commutative operations, even with collisions,<br>    can produce a correct state).</p><p>At a high level, all of the following (except UTXO) fall into one of<br>these two groups*:</p><ol><li><p>Speculative concurrency</p></li><li><p>Access Lists</p></li></ol><p>* there are certain methods (apart from the list above) that may not fall into either group, but the above classification is good enough for most approaches</p><h2 id="Discussing-Different-Approaches-to-L2-Parallelization"><a href="#Discussing-Different-Approaches-to-L2-Parallelization" class="headerlink" title="Discussing Different Approaches to L2 Parallelization"></a>Discussing Different Approaches to L2 Parallelization</h2><p>Let&#39;s continue to assess each of these groups, and find out what each of these approaches could mean for an EVM compatible Layer2, but before that, I bet you are thinking - what about the UTXO model?</p><h3 id="Discussion-1-Give-away-EVM-compatibility-x2F-equivalence"><a href="#Discussion-1-Give-away-EVM-compatibility-x2F-equivalence" class="headerlink" title="Discussion:1 Give away EVM compatibility&#x2F;equivalence"></a>Discussion:1 Give away EVM compatibility&#x2F;equivalence</h3><p>A chain&#x2F;L2 based on the UTXO model is easier to parallelize than an account based model. In the former, a transaction is generally a spending transaction and includes the unspent outputs that it is willing to spend (along with proper signatures of the inputs) for the transaction to be valid. This provides for a perfect opportunity to group together transactions that do not spend the same inputs, and execute them in parallel.</p><p>However, a chain based on UTXO model isn’t EVM equivalent, and loses out on the advantages of the existing Ethereum toolset, code and developers.</p><p><em>Fuel, Findora are some of the popular examples today, which enforce parallelization and utilize a UTXO model.</em></p><p><em>Additionally:</em></p><p><em>The UTXO model can be extended to have parallel validation with<br>utreexo-<br><a href="https://blog.bitmex.com/faster-blockchain-validation-with-utreexo-accumulators/">[https://blog.bitmex.com/faster-blockchain-validation-with-utreexo-accumulators/]</a></em></p><p><em>And, there are some chains that use both UTXO and account model like<br>Findora<br><a href="https://wiki.findora.org/docs/modules/prism/Overview/">[https://wiki.findora.org/docs/modules/prism/Overview/]</a></em></p><p><em>Smart contracts with UTXO account model and parallelization is also<br>possible<br><a href="https://forum.celestia.org/t/accounts-strict-access-lists-and-utxos/37">[https://forum.celestia.org/t/accounts-strict-access-lists-and-utxos/37]</a></em></p><p>But, even considering the successful implementation of these possibilities, the chain would still not be EVM equivalent.</p><p>Going back to the two groups we previously agreed upon, let’s discuss each of them in more detail-</p><h3 id="Discussion-2-Speculative-Concurrency"><a href="#Discussion-2-Speculative-Concurrency" class="headerlink" title="Discussion 2: Speculative Concurrency"></a>Discussion 2: Speculative Concurrency</h3><p>Speculative Concurrency appears to be a very popular strategy for parallel execution. A lot of research has been done, lots of ideas shared and several optimizations to speculative concurrency have been proposed.</p><p>The general idea of speculative concurrency is to execute transactions in parallel threads speculatively. If there were collisions (common state access) between these transactions, they are discarded and rerun sequentially later.<br><br>Adding on to this general idea, there have been several proposals towards improving Speculative concurrency such as - ‘Separation of nodes with speculative concurrency’ - which involves distributing the network into nodes, who have separate roles - mainly a distinction between those that participate in ordering and some that execute<br>For ex -<br><a href="https://sites.cs.ucsb.edu/~amiri/papers/oxii.pdf">[ParBlockchain]</a>,<br><a href="https://www.usenix.org/system/files/atc21-ponnapalli.pdf">[Rainblock]</a><br>(Validator nodes, IO nodes), Flow from Dapper Labs (separation of<br>consensus and compute)</p><p><a href="https://arxiv.org/pdf/2203.06871.pdf">[‘BlockSTM’]</a> is<br>another proposal that is ‘built around principles of Software<br>Transactional Memory’. It increases efficiency through dynamic<br>dependency estimation and a smart scheduler.</p><p>Some other ideas further add to this with dependency graphs, locks and<br>static&#x2F;bytecode analysis.<br><a href="https://www.microsoft.com/en-us/research/uploads/prod/2021/09/3477132.3483564.pdf">[Forerunner]</a><br>produces constraints based on multi future predictors and speeds<br>execution through the constraints.<br>But, while there are various proposals, it is challenging to accurately<br>evaluate its effectiveness in practice.</p><p>The current concerns with Speculative concurrency have been:</p><ul><li><p>It involves a lot of aborting tx and re-executing - which brings in<br>the need for pricing, otherwise this could open up to DoS attacks</p></li><li><p>Several of these methods might include changes on a protocol level</p></li><li><p>Speculative concurrency can suffer from penalties if a lot of tx<br>have conflicts and have to be scheduled again.</p></li><li><p>If the execution time of one tx in a batch is significantly more<br>than the others, speculative concurrency will yield only minor<br>benefits</p></li><li><p>It also depends on the activity of the network, types of<br>transactions and the size of the chain among other things, which<br>are hard to generalize, so the efficiency might not be<br>deterministic</p></li></ul><p>‘An Empirical Study of Speculative Concurrency in Ethereum Smart Contracts’ by Seraph et al (<a href="https://arxiv.org/pdf/1901.01376.pdf">https://arxiv.org/pdf/1901.01376.pdf</a>) is a great work of analysis on general speculative concurrency (without additional improvements) and its performance.</p><p>Some of their results have been “directly quoted” here:</p><ul><li><p><em>When txs are optimistically executed, conflict grows as blockchain<br>is more crowded, generally 35% clash rate</em></p></li><li><p><em>“Accurate static conflict analysis may yield a modest benefit”</em></p></li><li><p><em>“In high-contention periods, most contention resulted from a very<br>small number of popular contracts”</em></p></li><li><p><em>“Today, contract writers have no motivation for avoiding such<br>conflicts. It could be productive to devise incentives, perhaps in<br>the form of reduced gas prices, for contracts that produce fewer<br>data conflicts.”</em> (we will discuss about this under method access<br>boundaries)</p></li><li><p><em>“Speculative techniques typically work well when conflicts are<br>rare, but perform poorly when conflicts are common”</em></p></li></ul><p>The results of speculative concurrency could indeed be subjective, but to still find an estimation of the effects such a model could have - lets try looking back!</p><h4 id="Approximating-efficiency-of-general-speculative-concurrency-through-the-eyes-of-an-actively-operating-L2"><a href="#Approximating-efficiency-of-general-speculative-concurrency-through-the-eyes-of-an-actively-operating-L2" class="headerlink" title="Approximating efficiency of general speculative concurrency through the eyes of an actively operating L2:"></a>Approximating efficiency of general speculative concurrency through the eyes of an actively operating L2:</h4><p><a href="https://boba.network/">[Boba Network]</a> is an Optimistic Rollup with a considerable size (record) of transactions ranging throughout a year. It houses several defi dapps, games, tokens, hybrid compute applications which brings in a variety of types of transactions and thus is a suitable candidate for the L2 whose eyes we want to borrow.</p><p>From these past records of transactions on the network, we tried to extract information pertaining to each (transaction), namely the storage accesses (read&#x2F;write) in the hopes of estimating what efficiency speculative concurrency, if it were to exist, would bring to the network.<br>The results, that follow, are based on around 10,000 transactions from Boba’s history around block ranges (365k-370k) and (795k-800k). While the range is an indicator for expected behavior, there is scope for varying the ranges and comparing the results.</p><p>Boba, as is the case with Optimistic Rollup design, does not have a mempool currently that could clearly reveal the collisions based on the execution time by the sequencer. For approximation, transactions with close proximity have been grouped together (in groups of 3 and 5) as an estimate of what mempool&#x2F; concurrent transactions could look like (in the future).</p><p>Furthermore, collisions at two different levels have been represented distinctly:</p><p>i) Collisions at a contract access level (i.e. two or more transactions<br>that access the same addresses)</p><p>ii) Collisions at the storage level to check exact parallelizability<br>(i.e. two or more transactions that access the same storage slots of<br>these addresses)</p><p>The storage access information from these historical transactions also include operations on the storage slots that each transaction performs.</p><p>Between two transactions (tx1, tx2) and their operations on a specific storage slot-</p><p>(read, read) - works for concurrency</p><p>(read, write) and (write, read) - does not</p><p>(write, write) - mostly does not, unless operations are commutative</p><p><img src="/images/chart.png" alt="Chart"></p><p>*Total groups: number of groups of txs, (approximate grouping around proximity of tx - think blocks)</p><p>*Collision addresses: Groups that have collisions based on the addresses they access<br>If two or more txs in a group access a common addresses, we treat the group for having address collisions</p><p>Collision Storage slots: Groups that have collisions based on the storage slots of addresses they access. If two or more txs in a group access the same slots in the same addresses, we treat the group for having storage slot collisions*</p><p>Results from both of these block durations show that conflicts could be expected to be quite common (in this case), and general speculative concurrency (without improvements), though absolutely worth trying, could yield uncertain results.</p><h3 id="Discussion-3-Parallel-execution-with-Access-Lists"><a href="#Discussion-3-Parallel-execution-with-Access-Lists" class="headerlink" title="Discussion 3: Parallel execution with Access Lists"></a>Discussion 3: Parallel execution with Access Lists</h3><p>Access lists for parallel execution, proposed with ‘Easy parallelizability’ (<a href="https://github.com/ethereum/EIPs/issues/648">[https://github.com/ethereum/EIPs/issues/648]</a>) is one of the other lines of thinking about the problem. This involves creating a new tx type that allows users to specify the addresses and storage slots a transaction will access (read&#x2F;write), as a part of the transaction object. The transactions which have disjoint sets can then be executed in parallel.</p><p>Solana utilizes a system similar to access lists to enable parallel execution - <a href="https://medium.com/solana-labs/sealevel-parallel-processing-thousands-of-smart-contracts-d814b378192">[SeaLevel]</a> - where storage access info is embedded into the transaction as instructions (address and operation) to prefetch them for execution, <a href="https://sui.io/">[Sui]</a> has a similar approach to Solana.</p><p>The main problem with access lists is the difficulty of knowing which states and slots a transaction would affect in advance, without executing the transaction. There exists rpc endpoints like eth_createAccessLists (<a href="https://geth.ethereum.org/docs/rpc/ns-eth#eth_createaccesslist">[https://geth.ethereum.org/docs/rpc/ns-eth#eth_createaccesslist]</a>) which simulates to estimate access lists based on the state of the prior block. Static analysis of bytecode could also be effective in predicting access lists for a tx (<a href="https://github.com/alexchenzl/predict-al">[https://github.com/alexchenzl/predict-al]</a>)</p><p>Based on current community discussions and strategies, access lists appear to be the most promising and effective approach for enabling concurrency in the EVM. The usage of Access lists would typically not involve modifying the EVM or adding an additional layer to achieve the goal. Furthermore, it is closer to and can gain from several ongoing research efforts like Ethereum’s Statelessness&#x2F;Witnesses generation, which can be very close to obtaining strict access lists. Optional Access lists (<a href="https://eips.ethereum.org/EIPS/eip-2930">[https://eips.ethereum.org/EIPS/eip-2930]</a>) (<a href="https://eips.ethereum.org/EIPS/eip-2929#implementation">[https://eips.ethereum.org/EIPS/eip-2929]</a>) is already enforced on L1 allowing to prefetch states on the basis of optional access lists (although not for parallelization).</p><p>But in order to implement parallel execution, access lists have to be made strict - they should be maximally complete, so as to know exactly which transactions can be executed concurrently in parallel and avoid penalties for clashes while execution.</p><p>Currently Ethereum has ‘Optional Access Lists’ implemented through a new Tx type. But is it possible to make this a compulsion (strict) and enforce concurrency on the network? The assumptions are - a) toolset&#x2F;libraries&#x2F;rpc endpoints for the new tx type exists, but several of the most popular user wallet do not support the tx type yet, and at least some wallet will remain without support b) Users do not know or do not want to generate access lists or use scripts for sending txs. Furthermore, it is very difficult to know which states and slots a tx would affect without executing the transaction.</p><p>Broadly, the questions that must be answered for enforcing access lists are-</p><ol><li><p>How to generate an almost correct and complete access list?</p></li><li><p>Who generates access lists for the users?</p></li></ol><h3 id="What-if-wallets-add-support-for-the-tx-type-How-do-we-still-go-from-‘optional’-to-‘strict’-access-lists-and-enable-parallelization-on-L2"><a href="#What-if-wallets-add-support-for-the-tx-type-How-do-we-still-go-from-‘optional’-to-‘strict’-access-lists-and-enable-parallelization-on-L2" class="headerlink" title="What if wallets add support for the tx-type? How do we still go from ‘optional’ to ‘strict’ access lists and enable parallelization on L2?"></a>What if wallets add support for the tx-type? How do we still go from ‘optional’ to ‘strict’ access lists and enable parallelization on L2?</h3><p>If wallets were to enable the new transaction type, they might use `eth_createAccessList` to estimate the access list for the transaction. But, there is a possibility that this access list will not be accurate when the transaction is actually executed (since estimation would involve using a prior older state). And as per the demand, for transactions with strict access lists, any transaction with incomplete or incorrect (optional) access lists may be either reverted or queued to be executed sequentially. We could however still utilize Ethereum’s existing transaction types without having to create a new one, although,<br>It is important to maintain the distinction between the original &quot;optional&quot; element for prefetching states and the &quot;strict&quot; element where a transaction can be reverted if it does not provide a complete access list.</p><p>As a solution, an opt-in mechanism with a precompile on the network can be made use of to switch between optional (default) and strict (parallelization) choices for each user. Subsequently, when a user&#39;s access list choice is set to ‘strict’, any access outside the specified list should be unsuccessful.</p><h2 id="Two-Proposals"><a href="#Two-Proposals" class="headerlink" title="Two Proposals:"></a>Two Proposals:</h2><p>But, Irrespective of whether tools exist for the generation of access lists, the question remains: can we do more?</p><p>Here are two proposals.</p><h2 id="Proposal-1-Method-Access-Boundaries"><a href="#Proposal-1-Method-Access-Boundaries" class="headerlink" title="Proposal 1: Method Access Boundaries"></a>Proposal 1: Method Access Boundaries</h2><p>It is common for most transactions on a blockchain to primarily involve only a few types of smart contracts. If each transaction includes additional data in the form of access lists, it is likely that there will be repeated patterns of similar access lists with similar calls to contracts.</p><p>For a new line of thought, contracts themselves could be the ones to specify access lists, instead of the transaction sender in some cases. In other words, transactions are directed to accounts, and these accounts may have internal calls to other accounts. (we are interested in contract accounts only, since transactions from EOAs to EOAs already have all the information to parallelize), If each contract, on this chain of calls - were to have their own method access boundaries (meaning) - “could bound the addresses that each of the methods in the contract are able to access” (indefinite is a valid option) - we could be closer to finding out intersections and storage collisions between transactions before they are executed.</p><p>In addition to being a potential way to execute transactions concurrently, pre-specified method access boundaries could also be a way to enforce higher security standards for a contract by dictating what external methods&#x2F;addresses a contract is allowed&#x2F;supposed to call.</p><p>Several contracts do have complicated logic, there are contracts (or methods) that allow arbitrary calls, for instance contract wallets, there are proxy contracts which would not really benefit from method access boundaries (these will have ‘indefinite’ boundaries), but on the other hand a lot of general transactions would. Method Access Boundaries when used in combination with other parallelization techniques could result in an increased efficiency.</p><p>The goal is to encourage the creation of contracts that can be maximally parallelizable or have clearly defined method access boundaries, in order to improve scalability at the layer.</p><p>One such model including access boundaries is envisioned below.</p><p>Specifications:</p><ul><li>Have an optional extra storage layer for storing the access<br>boundaries of each contract account (specifically definite for<br>each of the methods of the contract account)</li></ul><p>Storage can be optional for nodes. This could also work with multiple sequencers, where some sequencers use this storage layer and could support method access boundaries for parallel execution. In case a user experiences transaction reversions, they could always direct their transactions to a general sequencer (that does not use or understand this extra storage layer).</p><ul><li><p>The method access boundaries could be centrally supplied&#x2F;generated<br>by the deployer.<br><br>Requirements for a contract to comply can be optional and can be<br>similar to verifying contracts - plus could be provable.<br>Contract fuzzing can be potentially utilized to find&#x2F;prove access<br>boundaries</p></li><li><p>In case the method access boundaries are found to be<br>incomplete&#x2F;wrong while execution, the sequencer would revert the<br>transaction (or) queue them to be executed sequentially. A default<br>route (not involving parallel execution) has to be maintained in<br>addition such that transaction chains involving those (incomplete)<br>contracts can be sent through the default route.<br><br>The maintained list would not be enough if the addresses it<br>interacts with, cannot be determined prior execution (delegate<br>call, arbitrary call etc)</p></li><li><p>This works for transactions that have information about all the<br>contract accounts involved in the transaction call chain. This is<br>easiest if the transaction does not involve calls to multiple<br>unknown addresses. Even one contract without information on the<br>transaction call stack could fail potential parallelizing<br>(fortunately, most of the common transactions we see in a network<br>do not involve such calls to several unknown addresses except that<br>of the senders).</p></li><li><p>Some access boundaries can have an additional spec - i.e<br>interactions with them could allow updation to the existing<br>boundaries of other methods of the contract. - for example, a<br>method that adds an ‘address’ value to the storage of the account.<br>The node that keeps track of the storage then, updates the<br>boundaries when calls are made to such methods</p></li><li><p>Some methods will not have access boundaries that can be specified -<br>in which case the external contract addresses in the boundaries<br>can be specified to be undetermined.</p></li></ul><p>For example, each method could have encoded access boundaries in the form</p><p><img src="/images/struct.png"></p><p>Where, “Type” determines if these boundaries can be written to, and R&#x2F;W determines read or write access to external contract</p><p>For a further simplified model, only the external contract accesses can be stored for the whole contract - (similar to how comparisons are in Easy parallelizability “v1” [EIP 648] )<br>for ex with-</p><p>tx1 &#x3D; A -&gt; B -&gt; C</p><p>tx2 &#x3D; E -&gt; F -&gt; D<br><br>can both be compared simply by comparing the set, and executed parallelly if there&#39;s no intersection</p><p>(S{A} U S{B} U S{C}) ∩ (S{E} U S{F} U S{D}) ≠ Φ</p><p>[Where S{X} is the method access boundaries of the method X]</p><h2 id="Proposal-2-Meta-AL-Transactions-and-Account-Abstraction"><a href="#Proposal-2-Meta-AL-Transactions-and-Account-Abstraction" class="headerlink" title="Proposal 2: Meta AL Transactions and Account Abstraction"></a>Proposal 2: Meta AL Transactions and Account Abstraction</h2><p>To reiterate one of the problems - people may have access to eth_CreateAccessLists which generates an estimated access list for a transaction (for the use in optional access list)- and conversion from ‘optional’ to ‘strict’ access list has been discussed before. Even with access to an rpc, most of the wallets today do not support an ethereum tx-type with access lists, and furthermore users might not know or want to write scripts for populating transactions with the respective access lists.</p><p>Moreover, since existing rpc methods can only give an estimation, users might not be well suited to provide access lists when the requirements are ‘strict’ - but at the same time specialized actors might be able to provide smarter access lists. Meta transactions can be a way to relieve the users from involvement with generation and supply of access lists.<br>We will start the discussion with meta-transactions (the way we know it) which are suitable for specific contract addresses, and later will move towards generalizing this for all contracts with ‘account abstraction’ methods.</p><p>So, to start with, access lists are a part of the tx object - and a relayer can be assigned the duty to add the access lists to a transaction upon forwarding a user signed message. This meta-transaction can then further be sent to the actual contract. Transactions to these contracts can be made cheaper - as incentivization, if they were to develop and have support for Meta AL transactions. This is similar to the gasless meta-transactions that some contracts are designed to support. But this approach isn’t very generalized and works only for contracts that opt-in and want to support parallelizability.</p><p>How do we generalize this? i.e allow this for all transactions throughout all contracts</p><p>Enter - <strong>Account Abstraction</strong></p><p>Account abstraction on L2 can enable forming transactions consisting of multiple signers, and custom logic for validating the tx, without the need for users to worry about providing access lists.<br><br>Account abstraction enables building custom transaction objects, logic, signature schemes and essentially revamping the kind of transaction&#x2F;operation a network supports and identifies, easily.</p><p>With a new userOp structure and wallet logic, any address would be able to send transactions with the responsibility of providing access lists to a second signer of their choice.</p><p>One such model that uses account-abstraction to support crowdsourced (and smart) meta access-lists could be as follows-</p><p>Specifications:</p><ul><li><p>Abstract out signature verification and requirements with account<br>abstraction ERC-4337(modified to include provider<br>address&#x2F;signature for each user operation). A smart contract<br>wallet level abstraction with relayers could also work, but does<br>not necessarily generalize it.</p></li><li><p>There exists a market of access-list providers whose job is to<br>provide access lists for transactions. (we can call them providers<br>in short). Even with access list estimation methods available,<br>these external providers could be a step more efficient in<br>providing appropriate access lists. For instance, dapps that also<br>provide their own provider, might be a preferred choice for<br>interactions with them.<br><br>They are rated&#x2F;priced at the efficiency with which they can<br>estimate access lists for transactions (smart providers may<br>include additional parameters or have their own logic of<br>computation, such that estimation is accurate most of the times).</p></li><li><p>Based on the customized signing conditions - each user operation<br>could specify the provider for access lists (or) each account<br>could set rotating signers for supplying access lists.</p></li><li><p>A user would sign and submit a transaction to the relayer (or) an<br>operation to their wallet specifying the provider, who in turn is<br>either specified by the user, or is selected for a specific epoch</p></li><li><p>The relayer&#x2F;provider then wraps the user tx along with the relevant<br>access list for the transaction and calls the User Account. The<br>User Account can then validate the transaction, signatures and<br>send it forward for execution.<br><br><img src="/images/aa_metal.png"></p></li></ul><p>Account abstraction is easier to implement for a L2 than the base Layer, and several L2s would move on to account abstraction at some point. If this can be utilized to enable third party providers&#x2F;relayers to provide ‘stricter’ access lists, a new market of providers could form. This probably can also be combined with ideas from ‘method access boundaries’, where projects could run their own relayers&#x2F;providers that could do the job of providing access lists for transactions to their contracts in the most efficient way.</p><p>While the Quest for Scalability is never ending, there is a clock thats ticking and will soon reveal a limit to how much networks can be scaled. Considering the current standards, that limit would not be very high. Some techniques such as these, or a combination of several, could in time, be the fuel that keeps the quest for Scalability running, and reset the clock, to delay the worry indefinitely for some time again in the future</p><h2 id="So-long-and-thanks-for-all-the-fish"><a href="#So-long-and-thanks-for-all-the-fish" class="headerlink" title="So long and thanks for all the fish"></a>So long and thanks for all the fish</h2><p>But this isn’t the end of exploring the potential of the topic, the intention is to start a conversation</p><ul><li><p>How efficient exactly could these methods be in practice?</p></li><li><p>How can we make parallel execution deterministic?</p></li><li><p>Several of these methods depend on existing ecosystem toolsets and<br>their compatibility. When and what kind of support will be<br>introduced in the future?</p></li><li><p>How big a change to the UX does this involve?</p></li></ul><p>As we wrap up for today, here are some questions that will come up over and over again, and probably the only way to get the answers will be to attempt implementing. Everyone of course will have different answers, because it truly isn&#39;t a one-size fits all problem. But the core of the matter is to acknowledge this as a nuance that can be solved, and take that first step on thinking about this together, today!</p>]]></content>
      
      
      
        <tags>
            
            <tag> EVM </tag>
            
            <tag> Rollup </tag>
            
            <tag> Research </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Quasar Pool: Extending Quasar with Liquidity Pools</title>
      <link href="/2021/03/24/quasar-pool/"/>
      <url>/2021/03/24/quasar-pool/</url>
      
        <content type="html"><![CDATA[<!-- ## Quasar Pool Design --><p>Find more details about the Quasar and its construction: <a href="/2021/01/18/quasar/" title="Quasar Fast Withdrawals: Instant Trustless Exits on Plasma">here</a><br>which explains a fully trustless model for enabling fast exits in Plasma (or an equivalent L2 without smart contracts) </p><p>This is a continuation that explains a variation in the construction of the quasar, trading off a bit on the trustless side for easier UX&#x2F;usability. (specifically this is the first implementation used by OmiseGo,)</p><p><em><strong>Note:</strong> the Quasar pool mentioned here is a plug-in to pool-in liquidity from several lenders and make things easy for someone running a Quasar contract. It is not an inherent requirement and the most ideal trustless Quasar should have funds pooled in only by the Quasar Owner.</em></p><h2 id="The-inception-of-a-Quasar-pool"><a href="#The-inception-of-a-Quasar-pool" class="headerlink" title="The inception of a Quasar pool:"></a>The inception of a Quasar pool:</h2><p>This is what a trustless Quasar should look like (this just shows the flows of the funds, some steps about Quasar interaction eg: ticket, challenges, ifeClaims haven’t been shown) <br><br><br><img src="https://user-images.githubusercontent.com/26090752/112024138-e5484100-8b59-11eb-979d-2d72e08c6c93.jpg" alt="quasar_diagram_without external_pool"></p><p>Here, the Quasar operator would put in funds on the ETH pool, and steps marked in ‘#’ are optional, the Quasar owner can do anything they want with the funds received on plasma after step 1. </p><p><em>Why should an ideal trustless Quasar have funds pooled in only by the Quasar operator?</em></p><p>A trustless Quasar shouldn’t need to trust anybody including the plasma operator. If you don’t trust the plasma operator, you are essentially contesting the validity of the tx inclusion proof (from step 2 of the above diagram). In that case you have a challenge period and prove any false claim wrong (after step 2). So, ideally since you are in control, you should have your own funds at stake, such that whenever there is a need, you actively challenge to protect your funds.</p><p>Now also note that the need for a challenge would only come up in case there is a invalid inclusion proof (in other words when the child chain is byzantine - a mass exit scenario)</p><p>If in an implementation the plasma operator is also running a Quasar - they trust themselves and hence have an opportunity to remove the challenge period from the Quasar!</p><p>This brings us to:</p><h2 id="Change-1-Quasar-with-no-challenge-period"><a href="#Change-1-Quasar-with-no-challenge-period" class="headerlink" title="Change 1. Quasar with no challenge period"></a>Change 1. Quasar with no challenge period</h2><p>So we have - a plasma operator that trusts themselves, that they won’t go byzantine and hence, pools in funds on the Quasar.</p><p>Now, this can be expanded to have people collectively pool-in funds for the Quasar pool, instead - which brings in participants to stay engaged with the pool and profits, and mostly to avoid putting up a large sum on the pool by the operator themselves. </p><p>So the trust model changes gradually from -</p><p><strong>Initially:</strong> Nobody trusts anybody.</p><p><strong>With no challenge period:</strong> plasma operator trusts -&gt; plasma operator</p><p><strong>With multiple suppliers pool:</strong> There are 2 choices:</p><ul><li><em>A) With collateral by operator:</em><br>   plasma operator trust -&gt; plasma operator</li><li><em>B) Without collateral by operator:</em><br>    Lenders trust -&gt; plasma operator</li></ul><p>In this variation we will assume and go with B)</p><p>This brings us to:</p><h2 id="Change-2-Quasar-pool-with-multiple-suppliers"><a href="#Change-2-Quasar-pool-with-multiple-suppliers" class="headerlink" title="Change 2. Quasar pool with multiple suppliers"></a>Change 2. Quasar pool with multiple suppliers</h2><p>The structure now looks like this <br><br><br><img src="https://user-images.githubusercontent.com/26090752/112024174-ee391280-8b59-11eb-8406-fa7d7d460e98.jpg" alt="quasar_diagram_with external_pool"></p><p>We can try and make it look similar to Compound (think the Quasar contract is the compound supply pool). The borrowers are the exiters, but the one who repays is - the trusted plasma operator.</p><p>Compound generates returns on the basis of block time. We do it on the basis of the number of exits. </p><h2 id="Returns-calculation"><a href="#Returns-calculation" class="headerlink" title="Returns calculation:"></a>Returns calculation:</h2><p>Every output you send to the Quasar owner on Plasma, you can withdraw<br><code>output_val - quasar_fee</code><br>from the Quasar contract on Ethereum. </p><p>This <code>quasar_fee</code> margin will be distributed among the pool of lenders in the ratio of each lender’s stake.<br>The calculation, we do it in a very similar way to a defi lending protocol, using qTokens.</p><p>Each token supplied to the pool has its exchangeRatio (<code>k</code>).</p><p>When liquidity is supplied to the pool, we mint <code>qOMG = OMG / k</code> for the supplier.</p><p>On withdrawal, qOMG is burnt and <code>OMG = qOMG * k</code> is withdrawn.</p><p>The exchangeRatio (<code>k</code>) determines the returns you get.</p><p>Fees accumulate in the pool every time a fast exit happens, and <code>k</code> updates to<br><code>k’ = f / Tq + k</code></p><p>Where </p><ul><li><code>f</code> &#x3D; fixed quasar_fee from every exit</li><li><code>Tq</code> &#x3D; total qTokens supply</li></ul><!-- Here is a proof for the equation https://github.com/omgnetwork/plasma-contracts/issues/728#issuecomment-760936145 --><h4 id="Proof-of-the-equation"><a href="#Proof-of-the-equation" class="headerlink" title="Proof of the equation"></a>Proof of the equation</h4><p>Return rates are dependent on the qtokens and the exchange rate k, for that specific token, at that point of time.<br>Deposits to the pool, for instance OMG will mint qOMG &#x3D; OMG&#x2F;k for the supplier<br>On Withdrawals, qOMG is burnt and OMG &#x3D; qOMG * k is withdrawn.<br>Fees accumulate in the pool every time a fast exit happens, and k updates to<br>    k’ &#x3D; f&#x2F;Tq + k</p><p><img src="https://user-images.githubusercontent.com/26090752/104730150-86cca400-575f-11eb-8c90-13ffe288df78.png" alt="proof1"><img src="https://user-images.githubusercontent.com/26090752/104730170-91873900-575f-11eb-9135-07b6779a7507.png" alt="proof2"><img src="https://user-images.githubusercontent.com/26090752/104730186-9815b080-575f-11eb-8061-5fbe84a9e1ed.png" alt="proof3"><img src="https://user-images.githubusercontent.com/26090752/104730202-9d72fb00-575f-11eb-8302-f11ccfe89b96.png" alt="proof4"></p><!-- Sample run, return calculationshttps://github.com/omgnetwork/brainstorm/tree/main/quasarPool_returns --><h3 id="Returns-Per-Exit"><a href="#Returns-Per-Exit" class="headerlink" title="Returns Per Exit"></a>Returns Per Exit</h3><p>Note, the fee has to be distributed for each qToken in the supply of the pool. (the qTokens denote the total supply of the pool)</p><p>So your return per exit &#x3D; no of qTokens you have * fee per qToken</p><p>If there are many lenders to the pool, the fee per qToken would be less<br>If there are small no of lenders, the fee per qToken is more.</p><p>We want the number of qToken in the pool to adjust automatically according to their return requirements.</p><p>When people supply, more qTokens.<br>when people withdraw, less qTokens in supply</p><h3 id="Returns-Per-Week"><a href="#Returns-Per-Week" class="headerlink" title="Returns Per Week"></a>Returns Per Week</h3><p>This gives a better idea of the movement in the pool as this brings the number of exits into the equation.<br>Also, a thing to note is that the returns are compounded.</p><p><code>Returns per week = (quasar_fee per exit * no of exits in the week * no of your qTokens) / qToken total supply  </code></p><p>This means the returns will increase&#x2F;decrease with the increase&#x2F;decrease in the number of exits</p><h3 id="Scenario-1"><a href="#Scenario-1" class="headerlink" title="Scenario 1"></a>Scenario 1</h3><p>When the number of exits increases, pool supply is idle:</p><p>Returns per lender increases, which may attract more lenders to supply,<br>which in turn could again normalise the return to the average rate,</p><p>If new lenders aren’t attracted, the existing suppliers enjoy higher rates.</p><h3 id="Scenario-2"><a href="#Scenario-2" class="headerlink" title="Scenario 2"></a>Scenario 2</h3><p>When the number of exits decreases, pool supply is idle:</p><p>Returns per lenders decrease, which could mean some lenders withdraw from the pool. The ones who stay in the pool enjoy higher returns. This normalises the return rate to average again</p><p>If lenders dont leave, all of them are happy with the lower return rate</p><h3 id="Scenario-3"><a href="#Scenario-3" class="headerlink" title="Scenario 3"></a>Scenario 3</h3><p>When no one supplies to the pool:</p><p>If even one person puts in a supply. He owns all of the qTokenSupply, gets all the returns to himself, which should be quite high.</p><p>This makes it a self-regulating pool, in terms of the need or use of fast exits in the system.</p><p><strong>The idea is that a higher number of fast exits would need a higher liquidity pool size, and scenario 1 shows that this will incentivize people to supply more</strong></p><p><strong>Similarly if there aren’t enough fast exit happening, we are better off with a small pool size(since that would be enough liquidity for a smaller number of exits)</strong></p><p>This sums up the tweaks for the construction, and if you are wondering - yes, this was the first iteration and has been implemented in code. <a href="https://github.com/omgnetwork/plasma-contracts/tree/master/plasma_framework/contracts/quasar">Find more about the implementation here</a>.</p>]]></content>
      
      
      
        <tags>
            
            <tag> Research </tag>
            
            <tag> Layer 2 </tag>
            
            <tag> Plasma </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Quasar Fast Withdrawals: Instant Trustless Exits on Plasma</title>
      <link href="/2021/01/18/quasar/"/>
      <url>/2021/01/18/quasar/</url>
      
        <content type="html"><![CDATA[<!-- Design: https://github.com/omgnetwork/plasma-contracts/blob/master/plasma_framework/docs/quasar/quasar-fast-withdrawals.md \ --><p><strong>Implementation:</strong> <a href="https://github.com/omgnetwork/plasma-contracts/tree/master/plasma_framework/contracts/quasar">https://github.com/omgnetwork/plasma-contracts/tree/master/plasma_framework/contracts/quasar</a></p><p><strong>&quot;</strong>Plasma is one of the earliest and among the most popular L2 scaling solutions in Ethereum. Plasma scales Ethereum by moving transactions to a UTXO based “child-chain” (chch) on top of Ethereum. All transactions on the chch are secured as per the consensus of the underlying layer - Ethereum, and a unique Exit Game design construct ensures funds are always protected from any third party-intervention or manipulation by the chch operator. </p><p>Part of this exit game design is the crucial component - “withdrawal period”. When users wish to withdraw funds from the Plasma chch, they initiate an exit process, wherein the process includes a time-based challenge period, set to 7 days. During this period, other participants of the network can challenge the validity of the exits by submitting a proof. If no challenges are raised within the timeframe, the exit is considered valid, allowing funds to be safely transferred back to the Ethereum mainnet. Hence, the withdrawal period of 7 days enables to protect the integrity of the L2 by disallowing any faulty withdrawals, with the assumption that 7 days is enough time for a fellow participant to react and submit a proof.</p><p>While the 7 day withdrawal period is of the utmost necessity, the same can be perceived as a potential limitation for users who want quick access to funds. That a user would wait 7 days for obtaining their funds when they move from L2&gt;L1 is an unrealistic expecation, and so, a solution in this regard is of the highest order to make Layer2’s synonymous with the ecosystem.<strong>&quot;</strong></p><p>This is an attempt to reduce the time needed to move funds from a Layer 2 to Layer 1 to &lt;&#x3D; 24 hrs. (The L2 in context is Plasma or an equivalent L2 without smart contracts)<br>This construction is a trustless way to exchange funds using a Layer 1 smart contract, which would enable almost anyone (i.e. not only limited to token-issuers or partners) to provide the service for incentives. The approach also pushes for bringing the liquidity providers to the exiters, hence eliminating the requirement of a token market.</p><h2 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h2><p>Exchanging&#x2F;Swapping assets is done with the help of transaction inclusion proofs</p><p>To put it briefly, the UX for Alice, who has PETH (ETH on Plasma Layer 2) and wants Layer 1 ETH is:</p><ul><li>Alice confirms the UTXO which she wants to exit (obtains a ticket from the Layer 1 contract)</li><li>Alice spends the UTXO in a Layer 2 transaction to the address of the Layer 1 contract owner</li><li>Then she waits for the transaction confirmation, provides inclusion proof to the contract and claims the funds on Layer 1</li></ul><p>Alice would pay a fee to the Layer 1 contract owner instead of bearing the gas cost for exiting the UTXO</p><h2 id="The-Process-in-Detail"><a href="#The-Process-in-Detail" class="headerlink" title="The Process in Detail"></a>The Process in Detail</h2><p>The Layer 1 contract is the main component which enables the trustless asset exchange. </p><p>The contract has to be setup by the owner using certain parameters to tweak its behaviour. So let’s call this setup a Quasar for now. Ideally, there will be multiple Quasars in the network, each of which provide a method for fast withdrawals with different properties such as waiting period or fee.</p><h3 id="Setting-Up"><a href="#Setting-Up" class="headerlink" title="Setting Up"></a>Setting Up</h3><p>Anyone can set up a Quasar, for any definite period of time and with whatever amount of liquidity.<br>The steps-</p><ol><li><p>Deploy the contract, setting the following attributes</p><ul><li>The Owner - the account which will receive the funds on Plasma; should be a fresh account with no history of incoming transactions.</li><li>Safe blocknum (upper-bound) - This is the latest decided safe block by the owner; to acknowledge tickets for UTXOs from this or older blocks; see <a href="#After-Operator-goes-Byzantine">reason</a></li><li>Waiting period - the time to wait from the contract receiving inclusion proofs to providing liquid funds; to protect against operator + user collusion only; see <a href="#Operator-allows-a-double-spend-transaction-of-Alice">reason</a></li></ul></li><li><p>Load the contract with Layer 1 funds for liquidity.</p></li></ol><h3 id="Using-and-Withdrawing"><a href="#Using-and-Withdrawing" class="headerlink" title="Using and Withdrawing"></a>Using and Withdrawing</h3><p>Alice has some PETH, this is the process she has to go through in order to get liquid funds instantly:</p><ol><li>Alice takes a note of the UTXO that she wants to exit. She has options to select any Quasar out there, comparing the waiting period and the safe blocknum upper-bounds for each of them.</li><li>Alice obtains a ticket from one of these Quasars, specifying her UTXO. The intention of the ticket is to reserve the amount from the contract. The ticket is valid for a certain period of time and can only be obtained for UTXOs which are within limits of the specified blocknum upper-bound; see <a href="#Owner-races-to-empty-liquid-funds">reason</a></li><li>After successfully obtaining the ticket, Alice spends the UTXO in a transaction to the Owner. The transaction should only include inputs owned by Alice; see <a href="#IFE-Claims">reason</a></li><li>After the transaction is confirmed, Alice submits a claim to the Quasar with the inclusion proof of the transaction.</li><li>The claim gets added to the Quasar’s queue with a very short waiting period. The waiting period gives the Quasar Owner an opportunity to challenge in case the Operator colludes with Alice</li><li>After the waiting period passes, upon executing the queue the contract sends rootchain funds to Alice</li></ol><h3 id="Maintainance"><a href="#Maintainance" class="headerlink" title="Maintainance"></a>Maintainance</h3><p>The Owner needs to maintain the Quasar contract from time-to-time in the following ways-</p><ul><li>The Owner has to update the safe blocknum upper-bound in intervals. This is totally dependent on the owner and in an ideal situation of multiple quasar options, even newer Utxos should be able to find one.</li><li>The waiting period can be freely set by the Owner. Since the waiting period is only useful in the rare case of the operator submitting invalid blocks(containing a double spent transaction), the period can be set to even lower than 24hrs, or can even be removed completely if Owner trusts the operator.</li><li>The Owner can periodically exit funds from plasma and use them to refill the Quasar’s liquidity pool.</li><li>The Owner can choose to empty the liquidity pool. To retract funds the owner should first freeze the contract which would stop giving away new tickets. The active tickets are still valid, and the remaining portion of liquid funds not covered by the tickets can be removed.</li></ul><h4 id="Mandatory-Actions"><a href="#Mandatory-Actions" class="headerlink" title="Mandatory Actions"></a>Mandatory Actions</h4><p>The Owner needs to necessarily -</p><ul><li>Challenge Claims - Challenge usual fast exit claim within the waiting period from the time of the claim</li><li>Challenge IFE-Claim - Challenge <a href="#IFE-Claims">IFE-Claims</a> within 7+x days (IFE finalization + buffer) from the time of the claim</li></ul><h2 id="Byzantine-State"><a href="#Byzantine-State" class="headerlink" title="Byzantine State"></a>Byzantine State</h2><p>The childchain is considered ‘byzantine’ if the operator performs an invalid action, such as submitting an invalid block. Normally this results in a mass exit i.e. everyone should exit their funds back to Layer 1.</p><h3 id="Freeze-during-Byzantine-State"><a href="#Freeze-during-Byzantine-State" class="headerlink" title="Freeze during Byzantine State"></a>Freeze during Byzantine State</h3><p>If the current state is determined to be Byzantine, the Owner should</p><ol><li>Avoid updating the Safe Blocknum upper-bound.</li><li>Freeze the contract to stop giving away new tickets.</li></ol><p>The existing active tickets however are valid and IFE-Claims can be used to recover these funds.</p><p>Note that freezing the contract has to be done within the Required Exit Period (<a href="#automating-maintainance-of-the-safe-blocknum-upper-bound">unless automatic safe block is set</a>), hence time-limited to one-week, but should be done sooner by the Owner to reduce the hassle.</p><h3 id="IFE-Claims"><a href="#IFE-Claims" class="headerlink" title="IFE-Claims"></a>IFE-Claims</h3><p>In the case that the operator doesn’t include Alice’s transaction in a block or is even withholding entire blocks, Alice won’t have the transaction inclusion proof to claim funds in the usual way from the Quasar. Similar to the MoreVP in-flight exit game, an IFE-Claim is the way to recover funds:</p><ol><li>Alice starts an IFE on the transaction to the Quasar. Note that an IFE has to be started before starting an IFE-claim, since starting an IFE on the transaction also proves it to be exitable.</li><li>Alice calls the IFEClaim method on the Quasar contract</li><li>Alice should not try to double spend the input that was spent with the transaction to ensure the transaction is always canonical</li><li>The Quasar owner has to Piggyback the output of this transaction</li><li>The IFE-claim on the Quasar here has a higher waiting period here (buffer + IFE finalization time) in order to have enough time to challenge if it is an invalid claim</li><li>The Quasar Owner gets the output after the IFE is finalized, and Alice receives the liquid funds from the Quasar contract after the waiting period</li></ol><p>Note that if Alice <em>does</em> double spend the input</p><ol><li>The double spend transaction is used to challenge the IFE and is determined to be non-canonical</li><li>The same transaction is used by the Quasar Owner to invalidate Alice’s IFE-claim on the Quasar contract</li><li>The Quasar owner is safe, but Alice may lose her funds.</li></ol><h2 id="Possible-Incentives-for-the-Owner"><a href="#Possible-Incentives-for-the-Owner" class="headerlink" title="Possible Incentives for the Owner"></a>Possible Incentives for the Owner</h2><h3 id="Fees-for-normal-fast-exits"><a href="#Fees-for-normal-fast-exits" class="headerlink" title="Fees for normal fast exits"></a>Fees for normal fast exits</h3><p>The fee should take into account:</p><ol><li><p>The cost of challenging in case the <a href="#Operator-allows-a-double-spend-transaction-of-Alice">Operator allows a double-spend transaction of Alice</a></p></li><li><p>The fee for providing the service - since the waiting period of every Quasar is customizable, the fee can be dependent on the waiting period, opening multiple options of usability. The fee can also alternatively be a cut from the amount.</p></li></ol><p>Another thing to note here, is since Alice doesn’t actually exit any funds from the child chain, she doesn’t have to pay for the cost of processing an exit (the bounty). Also the Quasar Owner has the option to merge multiple UTXOs on the child chain before exiting, which reduces gas. Altogether, less gas is spent on processing exits. Hence the Quasar Owner doesn’t need to include the cost of exiting the output in the fee.<br>The design of the fees should take this fact into consideration since, Alice would normally have to pay the bounty for a Standard Exit, but as an alternative here, she has to pay only a fee to the Quasar, which could ideally be of similar size.</p><h3 id="Fees-for-IFE-Claim"><a href="#Fees-for-IFE-Claim" class="headerlink" title="Fees for IFE-Claim"></a>Fees for IFE-Claim</h3><p>The IFE-Claim’s should be disincentivized by having a higher fee and should only be used when necessary. The IFE-Claim process requires the Owner to Piggyback. This cost should be borne by Alice and can be included with the fee to the Quasar.</p><p>The IFE-Claim is already disincentivized to some extent by having a higher waiting period than a normal IFE. So the fee for an IFE-Claim could simply include </p><ol><li>Fee of normal fast exit</li><li>Cost of piggybacking the ouptut</li><li>Cost of potentially challenging the IFE-Claim</li></ol><h2 id="Potential-Attacks-and-their-Mitigations"><a href="#Potential-Attacks-and-their-Mitigations" class="headerlink" title="Potential Attacks and their Mitigations"></a>Potential Attacks and their Mitigations</h2><h3 id="Attacks-by-Alice"><a href="#Attacks-by-Alice" class="headerlink" title="Attacks by Alice"></a>Attacks by Alice</h3><h4 id="DoS-tickets"><a href="#DoS-tickets" class="headerlink" title="DoS tickets"></a>DoS tickets</h4><p>Obtaining a ticket from a Quasar blocks the amount from the Quasar’s real limit. So obtaining several tickets without actually using them will block the capacity of the Quasar.<br>The solution is to have a bond, which can be taken for providing the ticket, and can be returned on claiming the tickets. This can be looked as to be similar to the exit bond. There can be other approaches too, where the service fee is taken while obtaining tickets.</p><h4 id="Ticket-for-a-fake-UTXO"><a href="#Ticket-for-a-fake-UTXO" class="headerlink" title="Ticket for a fake UTXO"></a>Ticket for a fake UTXO</h4><p>A ticket can be obtained for a fake UTXO, but while claiming funds the inclusion proof of the transaction between Alice and Owner is required.</p><h4 id="Alice-attempts-to-exit-from-the-UTXO-after-submitting-the-claim"><a href="#Alice-attempts-to-exit-from-the-UTXO-after-submitting-the-claim" class="headerlink" title="Alice attempts to exit from the UTXO after submitting the claim"></a>Alice attempts to exit from the UTXO after submitting the claim</h4><p>Alice needs the inclusion proof in order to claim liquid funds. So assuming the transaction to the Quasar owner was confirmed, if Alice tries to exit it will be challenged with that same inclusion proof.</p><p>If Alice starts an IFE-Claim, the same double spending transaction can be used to challenge both the IFE and the claim.</p><h4 id="Alice-uses-the-inclusion-proofs-of-same-UTXO-twice"><a href="#Alice-uses-the-inclusion-proofs-of-same-UTXO-twice" class="headerlink" title="Alice uses the inclusion proofs of same UTXO twice"></a>Alice uses the inclusion proofs of same UTXO twice</h4><p>Alice can get the ticket for any given UTXO, so it is possible for Alice to try claiming funds twice with the same inclusion proof.<br>The solution is to have a utxo map maintained by the Quasar which can eradicate this. Also in the case of Alice trying to use a different Quasar with an older proof will not succeed since the recipient of the UTXO will not be the Quasar owner.</p><h3 id="Attacks-by-the-Quasar-owner"><a href="#Attacks-by-the-Quasar-owner" class="headerlink" title="Attacks by the Quasar owner"></a>Attacks by the Quasar owner</h3><h4 id="Owner-races-to-empty-liquid-funds"><a href="#Owner-races-to-empty-liquid-funds" class="headerlink" title="Owner races to empty liquid funds"></a>Owner races to empty liquid funds</h4><p>For situations where The Owner immediately generates a ticket and tries to empty the liquidity funds before Alice claims, the owner still cannot generate a ticket with a value higher than the real(updated) capacity.</p><h4 id="Owner-retracts-liquid-funds-from-contract"><a href="#Owner-retracts-liquid-funds-from-contract" class="headerlink" title="Owner retracts liquid funds from contract"></a>Owner retracts liquid funds from contract</h4><p>The Owner cannot try to take away liquid funds and empty the contract between the time Alice takes to claim after transferring. Since the ticket reserves funds for Alice, Alice can safely extract funds as long as the ticket is still valid.</p><h3 id="Attacks-by-the-Operator"><a href="#Attacks-by-the-Operator" class="headerlink" title="Attacks by the Operator"></a>Attacks by the Operator</h3><h4 id="Operator-publishes-invalid-block"><a href="#Operator-publishes-invalid-block" class="headerlink" title="Operator publishes invalid block"></a>Operator publishes invalid block</h4><p>If Alice’s transaction to the Owner is included <em>before</em> the invalid transaction, the Owner can standard exit to get the funds</p><p>IF Alice’s transaction to the Owner is included <em>after</em> the invalid transaction, the Owner can in-flight exit to get the funds</p><h4 id="After-Operator-goes-Byzantine"><a href="#After-Operator-goes-Byzantine" class="headerlink" title="After Operator goes Byzantine"></a>After Operator goes Byzantine</h4><p>If the operator goes Byzantine but still submits blocks, the users can continue to make successive transaction and get proofs for them. This however, will not allow them to use the Quasars. For the older UTXOs (within the limit of the blocknum upper bound specified by the owner) that are transferred, the Owners could still exit, but for successive transfers after the operator goes byzantine, tickets will not be obtainable as it would be a UTXO from a blocknum that was after the safe upper-bound</p><h4 id="Operator-doesn’t-include-Alice’s-transaction-to-Owner"><a href="#Operator-doesn’t-include-Alice’s-transaction-to-Owner" class="headerlink" title="Operator doesn’t include Alice’s transaction to Owner"></a>Operator doesn’t include Alice’s transaction to Owner</h4><p>If the operator withholds the transaction, Alice can start an IFE-Claim to recover her funds</p><h4 id="Operator-allows-a-double-spend-transaction-of-Alice"><a href="#Operator-allows-a-double-spend-transaction-of-Alice" class="headerlink" title="Operator allows a double-spend transaction of Alice"></a>Operator allows a double-spend transaction of Alice</h4><p>This is the only rare chance which brings in the usage of the waiting period.</p><p>Alice spends UTXO1 in TX1 to Malorie, and then Alice colludes with the Operator to include a transaction TX2, this time to the Quasar Owner spending the UTXO1 again. Though the Owner cannot exit this, the contract would still allow Alice to claim liquid funds through UTXO1 (given UTXO1 was within the safe blocknum-upper bound)</p><p>The waiting period set for the Quasar protects against this. The Owner should validate their queue, and challenge Alice’s claim by revealing an older spend of UTXO1 within the waiting period. Since, this is rare, happening only when the Operator colludes with Alice, if someone trusts the Operator, or the Operator himself could run a Quasar without the need for validation, with a zero waiting period.</p><h2 id="Alternative-Modifications-to-the-approach"><a href="#Alternative-Modifications-to-the-approach" class="headerlink" title="Alternative Modifications to the approach"></a>Alternative Modifications to the approach</h2><h3 id="Single-Liquidity-Pool"><a href="#Single-Liquidity-Pool" class="headerlink" title="Single Liquidity Pool"></a>Single Liquidity Pool</h3><p>An alternative is to have a single liquidity pool instead of having seperate contracts with their own liquidity.</p><ul><li>fee can be distributed among liquidity providers</li><li>removes the requirement of running separate contracts for each liqudiity provider</li><li>however, this could potentially prevent from keeping the waiting period low. Since every swap is from the same pool, Liquidity provider’s are no more accountable for the safety of thier liquid funds.</li><li>can be an option when you want to delegate the task of challenging to a small set of other trusted user(s)</li></ul><h3 id="Automating-maintainance-of-the-Safe-Blocknum-upper-bound"><a href="#Automating-maintainance-of-the-Safe-Blocknum-upper-bound" class="headerlink" title="Automating maintainance of the Safe Blocknum upper-bound"></a>Automating maintainance of the Safe Blocknum upper-bound</h3><p>In the current design, there is a requirement for the Quasar owner to constantly keep updating the Safe Blocknum upper-bound.<br>An alternative could be -<br>Provide tickets for a UTXO if either one of these satisfy:</p><ul><li>UTXOs is older than (Latest_Block_timestamp - Buffer), ideally the buffer could take the value of the minimum validation period.<br> or</li><li>UTXO is from a safe block (determined by safe blocknum upper-bound) set by the Owner</li></ul><h3 id="Output-funds-in-different-form"><a href="#Output-funds-in-different-form" class="headerlink" title="Output funds in different form"></a>Output funds in different form</h3><p>Since the fast withdrawal way is essentially a swap of assets between users on different layers. The swap can be extended to provide fund outputs in any form. Instead of providing with Liquid funds, a deposit transaction to another Layer 2 could be created (enforcing a swap instead of an exit).</p>]]></content>
      
      
      
        <tags>
            
            <tag> Research </tag>
            
            <tag> Layer 2 </tag>
            
            <tag> Plasma </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>VIP Vault (or) Multiple Exit Vaults for Plasma</title>
      <link href="/2020/10/15/vip-exit-vault/"/>
      <url>/2020/10/15/vip-exit-vault/</url>
      
        <content type="html"><![CDATA[<!-- # VIP Vault (or) Multiple Exit Vaults --><p>Plasma is one of the earliest and among the most popular L2 scaling solutions in Ethereum. Plasma scales Ethereum by moving transactions to a UTXO based “child-chain” (chch) on top of Ethereum. All transactions on the chch are secured as per the consensus of the underlying layer - Ethereum, and a unique Exit Game design construct ensures funds are always protected from any third party-intervention or manipulation by the chch operator. </p><p>Part of this exit game design is the crucial component - “withdrawal period”. When users wish to withdraw funds from the Plasma chch, they initiate an exit process, wherein the process includes a time-based challenge period, set to 7 days. During this period, other participants of the network can challenge the validity of the exits by submitting a proof. If no challenges are raised within the timeframe, the exit is considered valid, allowing funds to be safely transferred back to the Ethereum mainnet. Hence, the withdrawal period of 7 days enables to protect the integrity of the L2 by disallowing any faulty withdrawals, with the assumption that 7 days is enough time for a fellow participant to react and submit a proof.</p><p>While the 7 day withdrawal period is of the utmost necessity, the same can be perceived as a potential limitation for users who want quick access to funds. That a user would wait 7 days for obtaining their funds when they move from L2&gt;L1 is an unrealistic expecation, and so, a solution in this regard is of the highest order to make Layer2’s synonymous with the ecosystem.</p><p>The following article is a proposal to solve the withdrawal problem, or propose a fast withdrawal method. This proposal has been written in the context of the MoreVp implementation of Plasma (OmiseGo), but can be freely applied to any other implentation or even a L2 with similar attributes.</p><h2 id="The-proposal"><a href="#The-proposal" class="headerlink" title="The proposal"></a>The proposal</h2><p>This is an approach to have a separate Vault + Exit Game with lower exit period which acts as an extension to the existing network. The main idea however, could be to have several of these Vaults that enable the possibility of having assets(utxo) which are exitable at different exit periods.</p><p>The main objectives of the VIP Vault are-</p><ul><li>Reduce Exit Period</li></ul><p>which in turn would require reducing the UTXO throughput, and making the vault exclusive by</p><ul><li>Limiting Access(entry barrier) and&#x2F;or incentivizing efficient output creations</li></ul><h2 id="Structure"><a href="#Structure" class="headerlink" title="Structure"></a>Structure</h2><p>The VIP Vault can be looked as a bucket within the existing framework and would require adding a vault with a new TxType and Registering an Exit Game for the TxType. </p><p>Assume- <br>VaultId 3 <br>supports TxType 3,4 <br>which supports spending, OutputType 3,4</p><p>Vault-3 has a lower exit-period and hence, a decoupling is necessary where the exit period is bound to the exit game for Txtype 3,4.<br>Depositing to the new vault will generate outputs of type 3 on the childchain. These outputs will be spendable through the Tx type 3. Note that an ETH output on Vault-1 is not the same as an ETH output on Vault-3, though they represent the same asset. TxType 3 uses the new exit game to exit.<br>Ideally, multiple Vaults with their own exit game independently exist while all the transactions are included in the same chch by the operator.</p><p>The prominent reason why someone with adequate funds would deposit in the vault would be to take advantage of fast withdrawing the remaining funds after doing transactions. Someone who would want to provide fast exitable outputs to other users should also find the Vault useful.</p><h2 id="Limiting-Access"><a href="#Limiting-Access" class="headerlink" title="Limiting Access"></a>Limiting Access</h2><p>Limiting access for the vault is necessary to keep the number of UTXOs low and -</p><ol><li>make sure there is enough time to challenge invalid exits</li><li>make sure there is enough time for everyone to exit in a mass-exit scenario</li></ol><p>Potential ways to reduce number of UTXOs-</p><ol><li><p>Have a lower bound on the deposit amount to the vault. this would only allow certain VIP rollers to access the vault and get their fast-exitable outputs. But the UTXOs can still be broken to several other UTXOs, while this is a good method to limit access, there is still possibility of having UTXOs cross the limit</p></li><li><p>Have a lower bound on the size of UTXO for the vault. The outputs from the Tx should each be higher than the minimum value. For example, if the lower bound is 5 ETH, an output of size 50 ETH can maximally be split into 10 UTXOs and no further.</p></li><li><p>Have at least one output from a tx to be of a certain minimum value. Though this could still result in number of UTXOs crossing limit, it is still safer than the first method.</p></li></ol><p>Additionally,</p><ol start="4"><li>Have dynamic fee for Tx similar to BTC, where the fee is dependent on the number of outputs. Making it cheaper to send 1 ETH in 1 UTXO than splitting it up into 10 UTXOs of 0.1 ETH each.</li></ol><h2 id="Reduce-Exit-Period"><a href="#Reduce-Exit-Period" class="headerlink" title="Reduce Exit Period"></a>Reduce Exit Period</h2><p>The exit period being the max of- <br>startExitTime + MFP <br>utxoCreationTime + MFP + REP</p><p>While we may not want to decrease REP too much, giving users time to react in a mass-exit scenario. A suitable time period can be caculated from the approximate expectations about the number of UTXOs for the vault</p><p>Approximately, <br>Time &#x3D; (0.5 * N) &#x2F; f</p><p>N &#x3D; number of UTXOs <br>f &#x3D; Fraction of a Block available</p><p>Reducing MFP, however should be better given there is a cap on the number of UTXOs and the watcher validates every MFP&#x2F;2</p><p>Case 1 <br>MFP is reduced to 4 days. REP is 7 days. <br>Outputs older than a week can exit within 4 days. Newer Outputs exit in 11 days from their creation. In case of mass exits users have 7 days to exit.<br>Watcher validates every 2 days.</p><p>Case 2 <br>MFP is reduced to 4 days. REP is 3 days. <br>Outputs older than 3 days can exit within 4 days. Newer ouput exit in 7 days from their creation. In case of mass exits user have 3 days to exit.</p><h2 id="Discarded-Ideas"><a href="#Discarded-Ideas" class="headerlink" title="Discarded Ideas"></a>Discarded Ideas</h2><p>Allow optional exits through contract, since outputs sent to a contract cannot be double spent. <br>Reason: This will not be protected against operator double spends or operator selective withholding tx to the contract. The Operator can also exit an invalid tx using the contract.</p>]]></content>
      
      
      
        <tags>
            
            <tag> Research </tag>
            
            <tag> Layer 2 </tag>
            
            <tag> Plasma </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Incentivized Third Party Collateralization for Stablecoins</title>
      <link href="/2020/04/21/stablecoin/"/>
      <url>/2020/04/21/stablecoin/</url>
      
        <content type="html"><![CDATA[<!-- # Incentivized Third Party Collateralization for Stablecoins --><h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a><em>Abstract</em></h2><p><strong>Stablecoins, which are primarily intended to function as a global reserve of value is insubstantial in their design and present many failure points. The mechanism to enable the coins to hold on-to a fixed value is by backing it with a collateral. Fiat collateralized stablecoins requires the users to trust a centralized entity, which breaks the total concept of decentralization. Crypto collateralized stablecoins has issues revolving high collateral requirements and risks of auto-liquidation. This Research Project aims to propose the use of an alternative architecture for the creation of a functional and secure stablecoin.</strong></p><h2 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1. Introduction"></a>1. Introduction</h2><p>Stablecoins are crypto tokens designed to eliminate volatility by backing it with an asset or fiat currency that remains stable. Further simplifying on the context - A stablecoin is just a token on the blockchain which maintains its value in accordance to a fiat government backed currency. Due to their property of non-volatility, which has been a pre-dominant problem in cryptocurrencies that exist today, it has garnered a lot of interest and appreciation.</p><p>However, Stablecoin designs which exist currently are insubstantial and present many failure points, which limits their general acceptability. Fiat collateralized stablecoins require users to trust a central entity, which breaks the total concept of decentralization. Non-collateralized stablecoins implementing seigniorage shares approach are still new and people actually trusting on them is questionable. Slightly better off the Crypto-Collateralized stablecoins, though providing a decentralized ecosystem are not that efficient in maintaining the stability and moreover has issues revolving high collateral requirements and liquidation risk in market crashes. Crypto-backed stablecoins like Dai, from Maker has achieved the feat of decentralization in the system [1], but has instability in their design principles –</p><p>• ~1.5 x collateral required</p><p>• Collateral can be auto liquidated</p><p>Summing up, all-together there is a dire need and opportunity to improve this piece of technology for global reach and acceptance.</p><h2 id="2-State-of-Existing-Problems"><a href="#2-State-of-Existing-Problems" class="headerlink" title="2. State of Existing Problems"></a>2. State of Existing Problems</h2><h3 id="A-Artificial-Markets"><a href="#A-Artificial-Markets" class="headerlink" title="A.  Artificial Markets"></a>A.  <strong>Artificial Markets</strong></h3><p>The market is dependent on supply-demand relationships. As most of the underlying cryptocurrencies are based on supply-demand relationships, proof of work provides the intended way to mine and produce new coins in the market. The difficulty of the system is adjusted and the target is set in every iteration to generate new coins. The target and reward re-adjustments provide an optimum way to attain stability. Artificial market calls for a solution which could hide the market problems by separating the concerns in token-economics [2].</p><h3 id="B-Market-Manipulation"><a href="#B-Market-Manipulation" class="headerlink" title="B.  Market Manipulation"></a>B.  <strong>Market Manipulation</strong></h3><p>Market manipulation allows for any entity to attempt to try and manipulate the market to alter the price of the stablecoins. Furthermore, the existential risk of market collapse also destroys the whole concept of a decentralized cryptocurrency. Controlling or influencing markets can be a cause to destroying the functionality of the whole ecosystem. Manipulating the markets will result in an improper game to play and will take the market down instantly. Summing up the weakness can be divide into two kinds of risk–</p><p>1. Risk of market collapse,</p><p>2. Oracle&#x2F;governance manipulation.</p><h2 id="3-An-Update-to-the-Architecture"><a href="#3-An-Update-to-the-Architecture" class="headerlink" title="3. An Update to the Architecture"></a>3. An Update to the Architecture</h2><p>The existing problems redirect to a new form of backing the architecture of stablecoins and one way of attaining all the benefits while solving all the problems is by creating collateral backing from third party investments. Broadly speaking, crypto-collateralized stablecoin where the collateral backing is from third party investments would allow a 1:1 collateralization ratio, and while also allowing to use the investor’s funds as a security if&#x2F;when the price of Ethereum goes down. The stability and the operation of the system is taken care of by the competitive investment process.</p><h3 id="A-The-process"><a href="#A-The-process" class="headerlink" title="A.  The process"></a>A.  <strong>The process</strong></h3><p>Users deposit ethers and get an equivalent amount of stablecoins for the collateral provided. Unlike Maker and other crypto backed stablecoins, no extra amount of ether has to be provided by the person. After the stablecoins are exchanged for the collateral amount, the coins and amount need to be secured by someone&#x2F; a group of people (crowdfunding) for volatility in the underlying crypto (Ethereum). The volatility is taken care of by the investment circle running in the background. The group of people who secured the stablecoin are entitled for the profit or loss (if any) in the underlying crypto and helps keep the stablecoins stable.</p><h3 id="B-Incentives-for-Investment"><a href="#B-Incentives-for-Investment" class="headerlink" title="B.  Incentives for Investment"></a>B.  <strong>Incentives for Investment</strong></h3><p>The algorithm provides better returns to the investors for providing a part of the collateral, than just holding on to their Ethereum (ETH)[3] The investment made by people is returned when the original stablecoins are redeemed. The amount returned to each of the investors is not linear to the fraction they provided the collateral for, but exponential for the part of the collateral they provided.</p><h3 id="C-External-Collateral-provision-from-the-Pool"><a href="#C-External-Collateral-provision-from-the-Pool" class="headerlink" title="C.  External Collateral provision from the Pool"></a>C.  <strong>External Collateral provision from the Pool</strong></h3><p>Providing the collateral for the stablecoin through a method of external funding backed by incentives offer for a structure which has two independent parts which function together to make the system functional. The external collateral pool being a separate entity for controlling the stability ensures that the instability of the market is not a concern for the proper functioning of the application. Separating the collateral pool and disconnecting all the relation with the other aspect of the stablecoin structure also allows the system to adapt to an alternate method of gathering collateral if required. This increases on the security aspect and makes sure that the system has a 100% uptime.</p><h2 id="4-Explaining-competition"><a href="#4-Explaining-competition" class="headerlink" title="4. Explaining competition"></a>4. Explaining competition</h2><h3 id="A-Anonymity-to-enforce-competition"><a href="#A-Anonymity-to-enforce-competition" class="headerlink" title="A.  Anonymity to enforce competition"></a>A.  <strong>Anonymity to enforce competition</strong></h3><p>The portion filled by other agents are anonymous. This provides with a competitive glance to filling up the maximal portion of the collateral amount. After all the agents are done filling up the collateral, an internal threshold is formed which partitions the point of profit&#x2F;loss on either side.</p><h3 id="B-Risk-x2F-Reward-Gains"><a href="#B-Risk-x2F-Reward-Gains" class="headerlink" title="B.  Risk&#x2F;Reward Gains"></a>B.  <strong>Risk&#x2F;Reward Gains</strong></h3><p><img src="/images/stablecoin_1.png" alt="Collateral Distribution"><br><strong>Fig 1: Collateral Pool structure</strong></p><p>The Anonymity brings in a concept of a strategic game built into the system. The lenders or collateral providers are provided to maximize their lending capacity considering the risk factor to it. The Rewards are directly related to the amount of investments, and not knowing what the other person has pooled in, makes sense to try and provide the maximal amount for pooling. Only the risk factor is the criteria for slashing the funds if a volatility issue comes up.</p><h3 id="C-Keeping-the-system-alive"><a href="#C-Keeping-the-system-alive" class="headerlink" title="C.  Keeping the system alive"></a>C.  <strong>Keeping the system alive</strong></h3><p>The competition among the lenders ensures a faster disbursal rate and almost provides with an instantaneous rate for providing with the capital. Crypto-collateralized stablecoins currently in existence provide with a method to collateralize instantly, but this mechanism comes closer while solving a larger scale of problem. The speed of disbursal increases with the competition which is further increased by trust in the system.</p><h2 id="5-Explaining-the-Money-Money-Algorithm"><a href="#5-Explaining-the-Money-Money-Algorithm" class="headerlink" title="5. Explaining the Money-Money Algorithm"></a>5. Explaining the Money-Money Algorithm</h2><h3 id="A-Designing-the-algorithm"><a href="#A-Designing-the-algorithm" class="headerlink" title="A.  Designing the algorithm"></a>A.  <strong>Designing the algorithm</strong></h3><p>The Algorithm takes care of the return distribution to the investors to the collateral pool. A strong and intelligent mechanism would motivate the investors and borrowers (the token buyers) to play a strategic game together and keep the system functional. The algorithm tends to provide returns in an exponential form with respect to the amount invested or the rate of involvement in the system.</p><h3 id="B-Description-of-the-design"><a href="#B-Description-of-the-design" class="headerlink" title="B.  Description of the design"></a>B.  <strong>Description of the design</strong></h3><p>The Algorithm shows the Distribution of the MARGIN (CURRENT ETH VALUE (-) STABLECOIN PURCHASED) in an Exponential way proportional to the Amount invested</p><p>Let,</p><p><em>Incentive[i] &#x3D; Incentive of individual investor</em></p><p><em>Lsum &#x3D; Total amount of collected incentives</em></p><p><em>filled[i] &#x3D; Portion filled by ith person</em></p><p><em>T &#x3D; Total Limit</em></p><p><em>A &#x3D; Amount cumulated</em></p><p><img src="/images/stablecoin_2.png" alt="calc"></p><h3 id="C-Optimal-Strategy"><a href="#C-Optimal-Strategy" class="headerlink" title="C.  Optimal Strategy"></a>C.  <strong>Optimal Strategy</strong></h3><p>The optimal strategy is to fill the highest fraction of the collateral amount to get huge profits in any. The competition among the investors for landing in the better side of the curve (filling the most parts of the collateral), will mean faster fulfillment. To further elaborate the exact advantages of the investors, listing out the two cases-</p><p>• <em>When ETH prices go up, people above the optimal point receive a higher profit than what they could have got by simply holding the ETH</em></p><p>• <em>When ETH prices go down, loss is very less compared to what they would have incurred by simply holding the ETH, if they are above the optimal point.</em></p><p>So, irrespective of the direction Ethereum (or the underlying asset) takes, the investor is in a favorable position in all conditions. There isn’t an associated luck factor, since it is clearly evident how a user can settle above the optimal point.</p><h2 id="6-Statistics"><a href="#6-Statistics" class="headerlink" title="6. Statistics"></a>6. Statistics</h2><p>The stablecoins structure proposed is non-linear type when it comes to the returns offered against investments. Because of the exponential structure of the profits there exists a threshold which has to be crossed in order to attain the profits. The profits are the reason which forces the lenders to push for the extra mile and go for the extra rewards. The competition for the extra reward motivates everyone to compete and increase the disbursal rate.</p><p><img src="/images/stablecoin_3.png" alt="Statistics"></p><p><strong>Fig 2: Comparing Incentives vs Investments</strong></p><p>The red graph plots the investments to the rewards for a cryptocurrency like Dai, while the blue graph plots the performance of the proposed platform, the point in the center specifies the central point or the threshold to land with extra rewards. Whether it’s a bull or bear crypto market, investing in the collateral pool will mean greater profits or lesser losses for investors, and strengthen a stablecoin architecture on the other side.</p><h2 id="7-Additional-Integrations"><a href="#7-Additional-Integrations" class="headerlink" title="7. Additional Integrations"></a>7. Additional Integrations</h2><h3 id="A-Introduction-of-a-Secondary-token"><a href="#A-Introduction-of-a-Secondary-token" class="headerlink" title="A.  Introduction of a Secondary token"></a>A.  <strong>Introduction of a Secondary token</strong></h3><p>A secondary token could be introduced to the ecosystem which could bind both the tokens together when maintaining stability. The secondary token could also be traded in a similar manner with the differences only being in the usage-</p><p>• Adjust the supply and demand manually by investors to maintain the stability of the primary currency</p><p>• Be used as a token to prevent or distribute losses in a better way in the situation of a high risk volatility</p><h3 id="B-Adding-a-lending-service-to-integrate-with-the-ecosystem"><a href="#B-Adding-a-lending-service-to-integrate-with-the-ecosystem" class="headerlink" title="B.  Adding a lending service to integrate with the ecosystem"></a>B.  <strong>Adding a lending service to integrate with the ecosystem</strong></h3><p>The stablecoin can be considered to be a loan itself, and stablecoins are provided in exchange for a collateral. The ecosystem already uses a method to provide collateral by third-party or entities who are not acquiring the stablecoins. The point of the collateral can be improvised to incorporate a lending structure [4] to make up for the losses by the market volatility. The amount existent in the collateral pool is a possible way to use the money to make up for losses in the system, or can be partnered with a microfinance entity. This also however, could bring up some issues, namely-</p><p>• Introduce a separate entity of trust with the collateral pool</p><p>• Provide a point of liquidity risk when collateral pool is depleted lower enough than the market capacity [5]</p><h2 id="8-Implementation-Discussion"><a href="#8-Implementation-Discussion" class="headerlink" title="8. Implementation Discussion"></a>8. Implementation Discussion</h2><p>Listing out the main components of the ecosystem:-</p><p>• Ethereum Smart Contracts</p><p>• ERC-20 token</p><p>• Wallet</p><p>• Interest distribution Algorithm</p><p>The stablecoin is designed to be functional at the Ethereum main network as an ERC-20 token standard. The token was created using solidity smart contracts and deployed on the Ethereum network. A secondary token can be created to maintain or further improve the stability of the existing token. The secondary token is the backing token and could also be an investment medium for several third parties. The smart contracts are the way to implement these tokens on the Ethereum framework. Smart contract is a piece of code that lives on the world-computer- the Ethereum Blockchain and maintains the state of the universe. The process of using the token i.e. buying and transferring can be done by interacting with the contract. Instead of the direct interaction with the contract, some users could also prefer to use a wallet service to avoid directly using the function calls of the contract. The application has been tested by creating a wallet, which provides a medium to interact with the contract and perform the necessary functions.</p><h2 id="9-Conclusion"><a href="#9-Conclusion" class="headerlink" title="9. Conclusion"></a>9. Conclusion</h2><p>This solution provides with a proper and unique strategy to encourage more people into the system to pool in money as the collateral, while providing them meaningful profits from the system and also stabilizing the system to maintain the stable value to a fiat currency. This not only helps in creating a stable ecosystem or currency structure but also increases economic activity and currency flow [6].</p><p>Additionally, the platform also ensures total functionality in all the discovered scenarios with proper integrity and completeness throughout all the components in this proposed system. The proposed system can be hence, easily integrated to an existing stablecoins structure or be created afresh.</p><h2 id="10-References"><a href="#10-References" class="headerlink" title="10. References"></a>10. References</h2><ol><li><p>Kenji Saito, Mitsuru Iwamura, “How to Make a Digital Currency on a<br>Blockchain Stable Future Generation Computer Systems, Volume 100,<br>2019, Pages 58-69.</p></li><li><p>Klages-Mundt, Ariah &amp; Minca, Andreea. (2019). (In) Stability for the<br>Blockchain: Deleveraging Spirals and Stablecoin Attacks.</p></li><li><p>Ingolf G.A. Pernice, Sebastian Henningsen, Roman Proskalovich,<br>Martin Florian, Hermann Elendner, Björn Scheuermann, Monetary<br>Stabilization in Cryptocurrencies - Design Approaches and Open<br>Questions, IEEE Crypto Valley Conference on Blockchain Technology<br>(CVCBT), 28^th^ May 2019</p></li><li><p>Black, Matthew &amp; Liu, TingWei &amp; Cai, Tony. (2019). Atomic Loans:<br>Cryptocurrency Debt Instruments, 16 Jan 2019.</p></li><li><p>Stjepan Begušić, Zvonko Kostanjčar, Momentum and liquidity in<br>cryptocurrencies, 1 Apr 2019</p></li><li><p>Peter Krafft, Nicolás Della Penna, Alex &#39;Sandy&#39; Pentland, An<br>Experimental Study of Cryptocurrency Market Dynamics, CHI &#39;18 2018</p></li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> Research </tag>
            
            <tag> Defi </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
